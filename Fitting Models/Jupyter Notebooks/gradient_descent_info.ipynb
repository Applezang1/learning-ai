{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bba0523b-f29c-4ba4-97ec-3ffc88b1a4ef",
   "metadata": {},
   "source": [
    "# Gradient Descent \n",
    "This notebook aims to help gain a mathematically understanding of gradient descent as well as functions needed for gradient descent (line search), subcategories of gradient descent (stochastic gradient descent), and additions to gradient descent (momentum, Adam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0cb9f5-97d4-4cfe-b67b-a46bb6eab88a",
   "metadata": {},
   "source": [
    "## Line Search Algorithm \n",
    "In order to understand how gradient descents work, a line search algorithm must first be defined. A line search algorithm is a function whose goal is to find the minimum of a 1D loss function (f(x)). \n",
    "\n",
    "<ins>Methods</ins>: \n",
    "A line search algorithm finds the x value that gives the minimum of a 1D loss function by defining four points (a, b, c, d) and repeatedly using the algorithm to narrow the value of the four points until it converges to the same value, which would be the predicted minimum. \n",
    "\n",
    "<ins>Rules</ins>: \n",
    "There are three rules in the line search algorithm that helps converge the four points to the same value that minimizes the loss function. The rules are: \n",
    "\n",
    "1) If the loss at point a is less than the loss at the other points, bring the other points halfway towards point a\n",
    "2) If loss(b) < loss(c), define the rightmost value (d) to become the c value and bring points b and c in between interval [a, c]. This is because if loss(b) < loss(c), the minimum is between interval [a, c]\n",
    "3) If loss(c) < loss(b), define the leftmost value (a) to become the new b value and bring points b and c in between interval [b, d]. This is because if loss(c) < loss(b), the minimum is between interval [b, d]\n",
    "\n",
    "<ins>Results</ins>: \n",
    "By repating the line search algorithm over a number of trials, we are able to converge the four points into the input value (x) that minimizes the 1D loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6959f70c-62a5-4975-bf29-aaa719b4d6a7",
   "metadata": {},
   "source": [
    "## Gradient Descent \n",
    "In neural networks, the gradient descent is a vector of all the partial derivatives of the loss function, each with respect to one parameter of the loss function. The vector is defined as: \n",
    "\n",
    "$$\n",
    "\\frac{\\partial L}{\\partial \\phi} =\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial L}{\\partial \\phi_0} \\\\\n",
    "\\frac{\\partial L}{\\partial \\phi_1} \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial L}{\\partial \\phi_N}\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "By computing the gradient descent vector, we are able to compute the direction where the loss function increases the most. Because we want to minimize the loss function, we multiply the gradient descent vector by -1 to compute the direction where the loss function decreases the most. \n",
    "\n",
    "Therefore using the gradient descent, we can update the parameters of the neural network to minimize the loss function in this format: \n",
    "$$\n",
    "\\phi \\leftarrow \\phi - \\alpha \\cdot \\frac{\\partial L}{\\partial \\phi}\n",
    "$$\n",
    "Note: $\\alpha$ is the step size, which is a value that determines the step of the parameter value towards that direction. Choosing the correct step size is really important because along with the direction, it is another factor that influences the decrease in the loss function.  \n",
    "\n",
    "<ins>Computing step size ($\\alpha$)</ins>: \n",
    "In order to compute the step size, we use the line search algorithm defined above. Define the 1D loss function for the line search algorithm as: \n",
    "$$\n",
    "\\phi(\\alpha) = L\\big(\\theta - \\alpha \\nabla_\\theta L(\\theta)\\big)\n",
    "$$\n",
    "We are able to define a 1D loss function in y-intercept format, where the amount of loss is only influenced by the step size in the negative gradient direction. Using the 1D loss function, we are able to perform a line search algorithm to find the alpha value that minimizes the 1D loss function the most, computing the ideal step size for the gradient descent.\n",
    "\n",
    "<ins>Result</ins>: \n",
    "Using the negative gradient and the step size, we are able to effectively update every single parameter of the neural network to decrease the loss function of the entire neural network model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c85c28-7aff-4bb3-a963-d1c6690db782",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Descent \n",
    "Stochastic gradient descent is a sub category of gradient descent. Stochastic gradient descent computes a vector of the partial derivatives of the loss function in respect to each parameter only for a randomly chosen batch of data. Stochastic gradient descent is defined as: \n",
    "$$\n",
    "\\phi_{t+1} \\leftarrow \\phi_t - \\alpha \\cdot \\sum_{i \\in \\mathcal{B}_t} \\frac{\\partial \\ell_i[\\phi_t]}{\\partial \\phi}\n",
    "$$\n",
    "Where:\n",
    "$$\n",
    "\\sum_{i \\in \\mathcal{B}_t} \\frac{\\partial \\ell_i[\\phi_t]}{\\partial \\phi}\n",
    "$$\n",
    "Represents the summation of all the partial derivatives of all the parameters for the chosen batch of data (stochastic gradient descent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93503208-5652-4a58-a9cb-03954fcd813c",
   "metadata": {},
   "source": [
    "## Momentum\n",
    "Momentum is a method of incorporating the past gradients of the neural network model into the current gradient step as a way of making more accurate and efficient steps towards the minimum of the loss function. \n",
    "\n",
    "Momentum is defined as:\n",
    "$$\n",
    "\\mathbf{m}_{t+1} \\;\\leftarrow\\;\n",
    "\\beta \\cdot \\mathbf{m}_t\n",
    "+ (1 - \\beta)\n",
    "\\sum_{i \\in \\mathcal{B}_t}\n",
    "\\frac{\\partial \\ell_i [\\boldsymbol{\\phi}_t]}{\\partial \\boldsymbol{\\phi}}\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "- $\\sum_{i \\in \\mathcal{B}_t}\\frac{\\partial \\ell_i [\\boldsymbol{\\phi}_t]}{\\partial \\boldsymbol{\\phi}}$ represents the summation of the gradients of all the parameters given a random batch of data\n",
    "\n",
    "- $\\beta$ represents the momentum constant, which determines how much of an effect past momentums have on the value of the next momentum\n",
    "\n",
    "- $\\mathbf{m}_t$ represents the current momentum (because momentum is recursive, it represents past gradients)\n",
    "\n",
    "The calculated momentum ($\\mathbf{m}_{t+1}$) is incorporated along with the step size ($\\alpha$) to adjust the parameters to decrease the loss of the neural network model. The adjustment of the parameter is represented as:\n",
    "$$\n",
    "\\boldsymbol{\\phi}_{t+1}\n",
    "\\;\\leftarrow\\;\n",
    "\\boldsymbol{\\phi}_t - \\alpha \\cdot \\mathbf{m}_{t+1},\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "- $\\boldsymbol{\\phi}_t$ is the current parameter value\n",
    "\n",
    "- $\\alpha$ is the step size\n",
    "\n",
    "- $\\mathbf{m}_{t+1}$ is the calculated momentum\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c183999c-3d4a-4919-888c-98dc428b7ccb",
   "metadata": {},
   "source": [
    "## Nestrov Accelerated Momentum \n",
    "Nestrov accelerated momentum is a sub category of momentum that calculates the momentum of the next predicted point instead of the current point. \n",
    "\n",
    "Nestrov accelerated momentum is defined as: \n",
    "$$\n",
    "\\mathbf{m}_{t+1} \\;\\leftarrow\\;\n",
    "\\beta \\cdot \\mathbf{m}_t\n",
    "+ (1 - \\beta)\n",
    "\\sum_{i \\in \\mathcal{B}_t}\n",
    "\\frac{\\partial \\ell_i [\\boldsymbol{\\phi}_t - \\alpha \\beta \\cdot \\mathbf{m}_t]}{\\partial \\boldsymbol{\\phi}}\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "- $\\sum_{i \\in \\mathcal{B}_t}\\frac{\\partial \\ell_i [\\boldsymbol{\\phi}_t - \\alpha \\beta \\cdot \\mathbf{m}_t]}{\\partial\\boldsymbol{\\phi}}$ represents the summation of the gradients of the loss at the next predicted point\n",
    "\n",
    "- $\\beta$ represents the momentum constant, which determines how much of an effect past momentums have on the value of the next momentum\n",
    "\n",
    "- $\\mathbf{m}_t$ represents the current momentum (because momentum is recursive, it represents past gradients)\n",
    "\n",
    "Because Nestrov accelerated momentum calculates the momentum of the next predicted point, the equation considers the gradient of the next predicted point into the value of the output momentum \n",
    "\n",
    "The calculated momentum ($\\mathbf{m}_{t+1}$) is incorporated along with the step size ($\\alpha$) to adjust the parameters to decrease the loss of the neural network model. The adjustment of the parameter is represented as:\n",
    "$$\n",
    "\\boldsymbol{\\phi}_{t+1}\n",
    "\\;\\leftarrow\\;\n",
    "\\boldsymbol{\\phi}_t - \\alpha \\cdot \\mathbf{m}_{t+1},\n",
    "$$\n",
    "Where: \n",
    "\n",
    "- $\\boldsymbol{\\phi}_t$ is the current parameter value\n",
    "\n",
    "- $\\alpha$ is the step size\n",
    "\n",
    "- $\\mathbf{m}_{t+1}$ is the calculated momentum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ee2422-1bda-4939-aa5c-c5639932a4e6",
   "metadata": {},
   "source": [
    "## Adaptive Moment Estimation (Adam)\n",
    "For stochastic gradient descent, large gradients from large batches of data lead to large adjustements in parameter value while small gradients from small batches of data lead to small adjustments in parameter value. This is not an ideal behavior and adaptive moment estimation normalizes the gradient (gives it consistent magnitude) so that constant adjustments to parameter values are made regardless of gradient size. \n",
    "\n",
    "The gradient is normalized through: \n",
    "$$\n",
    "\\mathbf{m}_{t+1} \\leftarrow \\frac{\\partial L[\\phi_t]}{\\partial \\phi}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_{t+1} \\leftarrow \\left( \\frac{\\partial L[\\phi_t]}{\\partial \\phi} \\right)^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\mathbf{m}_{t+1}}{\\sqrt{\\mathbf{v}_{t+1}} + \\epsilon}\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "- $\\mathbf{m}_{t+1}$ represents the current gradient\n",
    "\n",
    "- $\\mathbf{v}_{t+1}$ represents the pointwise squared gradient (essentially just the square of $\\mathbf{m}_{t+1}$)\n",
    "\n",
    "- $\\frac{\\mathbf{m}_{t+1}}{\\sqrt{\\mathbf{v}_{t+1}} + \\epsilon}$ represents the normalized gradient (gradient with consistent magnitude)\n",
    "\n",
    "Using the normalized gradient, the adjustment of the parameter value for a gradient descent is represented as:\n",
    "\n",
    "$$\n",
    "\\phi_{t+1} \\leftarrow \\phi_t - \\alpha \\cdot \\frac{\\mathbf{m}_{t+1}}{\\sqrt{\\mathbf{v}_{t+1}} + \\epsilon}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $\\boldsymbol{\\phi}_t$ is the current parameter value\n",
    "\n",
    "- $\\alpha$ is the step size\n",
    "\n",
    "- $\\frac{\\mathbf{m}_{t+1}}{\\sqrt{\\mathbf{v}_{t+1}} + \\epsilon}$ is the normalized gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19971c85-6ee1-49cf-a02d-40d4346ca692",
   "metadata": {},
   "source": [
    "## Adam with Momentum \n",
    "In addition, momentum can be incorporated to the adaptive moment estimation to further improve adjustments to the parameter values. \n",
    "\n",
    "With the addition of momentum, the new gradient is represented as:\n",
    "$$\n",
    "\\mathbf{m}_{t+1} \\leftarrow \\beta \\cdot \\mathbf{m}_t + (1 - \\beta) \\frac{\\partial L[\\phi_t]}{\\partial \\phi}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_{t+1} \\leftarrow \\gamma \\cdot \\mathbf{v}_t + (1 - \\gamma) \\left( \\frac{\\partial L[\\phi_t]}{\\partial \\phi} \\right)^2\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "- $\\mathbf{m}_{t+1}$ represents the gradient with momentum (weighted summation of all the past gradients)\n",
    "\n",
    "- $\\mathbf{v}_{t+1}$ represents the pointwise squared gradient with momentum (weighted summation of all the past gradients)\n",
    "\n",
    "- $\\beta$ and $\\gamma$ represent momentum coefficients, which determines how much of an effect past momentums have on the current momentum\n",
    "\n",
    "Because the momentum starts off at 0, the current definition of momentum will make it so that the first couple of gradient descent steps have no effect on the parameters (since the past momentum is too small). To fix this, incorporate a bias \n",
    "\n",
    "The bias-corrected gradients are represented as:\n",
    "$$\n",
    "\\hat{\\mathbf{m}}_{t+1} \\leftarrow \\frac{\\mathbf{m}_{t+1}}{1 - \\beta^{t+1}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\hat{\\mathbf{v}}_{t+1} \\leftarrow \\frac{\\mathbf{v}_{t+1}}{1 - \\gamma^{t+1}}\n",
    "$$\n",
    "\n",
    "Where: \n",
    "\n",
    "- $\\hat{\\mathbf{m}}_{t+1} \\leftarrow \\frac{\\mathbf{m}_{t+1}}{1 - \\beta^{t+1}}$ represents the bias-corrected gradient with momentum (weighted summation of all the past gradients)\n",
    "\n",
    "- $\\hat{\\mathbf{v}}_{t+1} \\leftarrow \\frac{\\mathbf{v}_{t+1}}{1 - \\gamma^{t+1}}$ represents the bias-corrected pointwise squared gradient with momentum (weighted summation of all the past gradients)\n",
    "\n",
    "Using the biased momentum, we can now normalize the gradient. The normalized gradient is represented as:\n",
    "\n",
    "$$\\frac{\\hat{\\mathbf{m}}_{t+1}}{\\sqrt{\\hat{\\mathbf{v}}_{t+1}} + \\epsilon}$$\n",
    "\n",
    "Where: \n",
    "\n",
    "- $\\epsilon$ is a constant that prevents the division by 0\n",
    "\n",
    "The normalized gradient is used in the gradient descent step to adjust the value of the parameter. It is represented by:\n",
    "\n",
    "$$\n",
    "\\phi_{t+1} \\leftarrow \\phi_t - \\alpha \\cdot \\frac{\\hat{\\mathbf{m}}_{t+1}}{\\sqrt{\\hat{\\mathbf{v}}_{t+1}} + \\epsilon}\n",
    "$$\n",
    "\n",
    "- $\\boldsymbol{\\phi}_t$ is the current parameter value\n",
    "\n",
    "- $\\alpha$ is the step size\n",
    "\n",
    "- $\\frac{\\hat{\\mathbf{m}}_{t+1}}{\\sqrt{\\hat{\\mathbf{v}}_{t+1}} + \\epsilon}$ is the normalized gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdb7901-0bf6-4b6d-ad0a-1d5d149964ee",
   "metadata": {},
   "source": [
    "## Initialization \n",
    "For gradient descents, we need to ensure that we choose sensible parameters in order to prevent the gradient from vanishing (when computed gradients are too small) or to prevent the gradient from exploding (when computed gradients are too big). This can be applied to gradients for the forward pass as well as gradients for the backward pass \n",
    "\n",
    "To compute the ideal variance between the parameter values for forward passes, use the formula: \n",
    "$$\n",
    "\\sigma_{\\Omega}^2 = \\frac{2}{D_{h}}\n",
    "$$\n",
    "Where: \n",
    "\n",
    "- $D_{h}$ is the number of inputs to the specific hidden unit\n",
    "\n",
    "- $\\sigma_{\\Omega}$ is the computed variance of the parameters\n",
    "\n",
    "To compute the ideal variance between the parameter values for backward passes, use the formula:\n",
    "$$\n",
    "\\sigma_{\\Omega}^2 = \\frac{2}{D_{h'}}\n",
    "$$\n",
    "Where: \n",
    "\n",
    "- $D_{h'}$ is the number of hidden units that the specific hidden unit influences\n",
    "\n",
    "To compute the ideal variance between the parameter values while taking into account both the forward and backward passes, use the formula: \n",
    "$$\n",
    "\\sigma_{\\Omega}^2 = \\frac{4}{D_h + D_{h'}}\n",
    "$$\n",
    "Which takes the average of the input and output dimension to compute the ideal variance between the parameter values\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RDKit)",
   "language": "python",
   "name": "rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
