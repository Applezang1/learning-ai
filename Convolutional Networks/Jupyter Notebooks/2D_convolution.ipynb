{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1916c431-4bb1-42d8-9c3a-4407156be10e",
   "metadata": {},
   "source": [
    "# 2D Convolution\n",
    "This notebook aims to help gain a better understanding of 2D convolution by defining a convolution function of varing stride, input, and output layers and comparing its accuraccy by comparing it to PyTorch's convolution function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda2eb70-2c52-4cb8-b314-c9a6be3eec66",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import the libraries needed to define the convolution function of varing stride, input, and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af92fb5a-5089-483d-bbf2-1e10397c9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7718be10-cc3f-4220-b549-98e2fb28be35",
   "metadata": {},
   "source": [
    "### Define PyTorch Convolution\n",
    "Define a function that uses PyTorch to perform convolution for a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22eb2089-8c20-493f-9c9b-d2a1ffc930ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set print size of PyTorch output\n",
    "np.set_printoptions(precision=3, floatmode=\"fixed\")\n",
    "torch.set_printoptions(precision=3)\n",
    "\n",
    "# Perform convolution using PyTorch\n",
    "def conv_pytorch(image, conv_weights, stride=1, pad =1):\n",
    "  # Convert image and kernel to tensors\n",
    "  image_tensor = torch.from_numpy(image) # (batchSize, channelsIn, imageHeightIn, =imageWidthIn)\n",
    "  conv_weights_tensor = torch.from_numpy(conv_weights) # (channelsOut, channelsIn, kernelHeight, kernelWidth)\n",
    "  # Undergo convolution\n",
    "  output_tensor = torch.nn.functional.conv2d(image_tensor, conv_weights_tensor, stride=stride, padding=pad)\n",
    "  # Convert back from PyTorch and return \n",
    "  return(output_tensor.numpy()) # (batchSize channelsOut imageHeightOut imageHeightIn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74c6500-2190-416b-87c8-5e4aaec4e63a",
   "metadata": {},
   "source": [
    "### Define Numpy Convolution\n",
    "Define a function that uses Numpy functions to perform convolution for a random image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8f93759-f454-492f-b140-d6d1e4a7bca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_numpy_1(image, weights, pad=1):\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Determine sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Determine size of output arrays\n",
    "    imageHeightOut = np.floor(1 + imageHeightIn - kernelHeight).astype(int)\n",
    "    imageWidthOut = np.floor(1 + imageWidthIn - kernelWidth).astype(int)\n",
    "\n",
    "    # Define an array structure for the output of the CNN\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    # For the location of each pixel on the final image\n",
    "    for c_y in range(imageHeightOut):\n",
    "      for c_x in range(imageWidthOut):\n",
    "        # For the location of each pixel on the kernel\n",
    "        for c_kernel_y in range(kernelHeight):\n",
    "          for c_kernel_x in range(kernelWidth):\n",
    "            # Compute the value of the pixel and the value of the corresponding kernel weight\n",
    "            this_pixel_value = image[0, 0, c_kernel_y+c_y, c_kernel_x+c_x]\n",
    "            this_weight = weights[0, 0, c_kernel_y, c_kernel_x]\n",
    "\n",
    "            # Multiply the value of the kernel by the value at the location of the pixel to compute the activation map\n",
    "            out[0, 0, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c06e7cf-c374-4bf6-9613-c88b5bfcec09",
   "metadata": {},
   "source": [
    "### Initialize Hyperparameters\n",
    "Initialize hyperparameters for the convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "323e71c8-cb10-4258-93ff-04bb5fd22859",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n_batch = 1\n",
    "image_height = 4\n",
    "image_width = 6\n",
    "channels_in = 1\n",
    "kernel_size = 3\n",
    "channels_out = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd1d1ea-4f98-473f-af72-2ea5aafd8edc",
   "metadata": {},
   "source": [
    "### Define Input \n",
    "Define a random image as the input for the convoluution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66b3f11-9e57-4a0f-ab55-dacbfcaedada",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3471f26b-431a-42c1-b3f2-2a91704d4489",
   "metadata": {},
   "source": [
    "### Initialize Kernel Weights\n",
    "Initialize the weights of the kernel for the convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba7eff9e-e6c2-4e2c-915f-93479b8d7b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335fa323-8a1f-49f5-9fce-13d4290febe2",
   "metadata": {},
   "source": [
    "### Convolution (PyTorch)\n",
    "Perform PyTorch's convolution function on the input image and print the feature map (output of the convolution function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "facd7bd0-a308-4a6f-be93-378b918b43d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[-0.92877074 -2.76029052  0.71617666  0.11420725  0.5596409\n",
      "    -0.38718181]\n",
      "   [-1.51472398  0.28314694  1.00809468  0.46584486 -1.0939884\n",
      "     2.00448021]\n",
      "   [-1.63398828  3.55485207 -2.15395759 -0.89198292 -1.85607063\n",
      "     2.29928377]\n",
      "   [ 0.56543283 -0.94654296 -0.62942895  2.99601051 -1.81129165\n",
      "    -0.53341   ]]]]\n"
     ]
    }
   ],
   "source": [
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cdb834-a320-46cf-af5e-4baa7e28ec81",
   "metadata": {},
   "source": [
    "### Convolution (Numpy)\n",
    "Perform Numpy's convolution function on the input image and print the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "897bb78f-2560-4160-bc3b-f4cd1eda1b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy results\n",
      "[[[[-0.9287708  -2.7602906   0.7161767   0.1142073   0.5596409\n",
      "    -0.38718182]\n",
      "   [-1.5147239   0.28314698  1.0080947   0.46584484 -1.0939885\n",
      "     2.0044804 ]\n",
      "   [-1.6339881   3.554852   -2.1539576  -0.8919829  -1.8560706\n",
      "     2.2992837 ]\n",
      "   [ 0.56543285 -0.946543   -0.629429    2.9960103  -1.8112916\n",
      "    -0.53341   ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy results\")\n",
    "conv_results_numpy = conv_numpy_1(input_image, conv_weights)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f868c-ae1b-4183-b0dd-74f0675c5fd4",
   "metadata": {},
   "source": [
    "### Define Numpy Convolution (Stride)\n",
    "Define a function that uses Numpy functions to perform convolution for a random image, with the incorporation of a stride for the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5364cf6e-1ab5-43ac-8d1b-59503557c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_numpy_2(image, weights, stride=1, pad=1):\n",
    "\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Determine sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Determine size of output arrays\n",
    "    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n",
    "    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n",
    "\n",
    "    # Define an array structure for the output of the CNN\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    # For the location of each pixel on the final image\n",
    "    for c_y in range(imageHeightOut):\n",
    "      for c_x in range(imageWidthOut):\n",
    "        # For the location of each pixel on the kernel\n",
    "        for c_kernel_y in range(kernelHeight):\n",
    "          for c_kernel_x in range(kernelWidth):\n",
    "            # Compute the value of the pixel and the value of the corresponding kernel weight\n",
    "            # Incorporate stride towards the location of the pixel\n",
    "            this_pixel_value = image[0, 0, c_kernel_y+c_y*stride, c_kernel_x+c_x*stride]\n",
    "            this_weight = weights[0, 0, c_kernel_y, c_kernel_x]\n",
    "\n",
    "            # Multiply the value of the kernel by the value at the location of the pixel to compute the activation map\n",
    "            out[0, 0, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n",
    "\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4e8c38-7cb1-4c0a-b1c6-5810466b2e51",
   "metadata": {},
   "source": [
    "### Initialize Hyperparameters\n",
    "Initialize hyperparameters for the convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecf4eed4-b881-4da5-941f-165f8372616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n_batch = 1\n",
    "image_height = 12\n",
    "image_width = 10\n",
    "channels_in = 1\n",
    "kernel_size = 3\n",
    "channels_out = 1\n",
    "stride = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2fcbd9-a339-4b51-82f8-1ec64f93bcbe",
   "metadata": {},
   "source": [
    "### Define Input \n",
    "Define a random image as the input for the convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e99753b-4e2b-43dd-aa16-4e7edc522a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6737cb0d-4c85-4f1e-b740-bfbac6a5be26",
   "metadata": {},
   "source": [
    "### Initialize Kernel Weights\n",
    "Initialize the weights of the kernel for the convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e71b435-5f60-45b3-88ce-e63a01dbb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d228ca4-1d51-4142-83a3-24a49f4d6046",
   "metadata": {},
   "source": [
    "### Convolution (PyTorch)\n",
    "Perform PyTorch's convolution function on the input image and print the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5b597fbe-961d-4b36-9c6b-083c897fb3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[-0.80936502 -4.55000504 -5.48644408 -9.50590007 -4.5119328 ]\n",
      "   [-0.05546526  1.14484207 -5.38831003 -3.9102454   0.09650551]\n",
      "   [-0.18614325  0.65958396  1.62966335  2.27526627  4.87444365]\n",
      "   [ 2.38590982 -0.22541781  3.28823207 -4.23915446 -1.4026945 ]\n",
      "   [ 0.82496306  1.71026929 -3.24597272  3.24605864  1.7087309 ]\n",
      "   [ 0.8088478   3.69534498  3.49057599 -2.11278279 -2.71367209]]]]\n"
     ]
    }
   ],
   "source": [
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca36f18-650f-4365-b3be-de26aa8a92e5",
   "metadata": {},
   "source": [
    "### Convolution (Numpy)\n",
    "Perform Numpy's convolution function on the input image and print the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9bc40763-1940-4320-ba10-593037cbfebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy results\n",
      "[[[[-0.8093651  -4.550005   -5.4864435  -9.505899   -4.511933  ]\n",
      "   [-0.05546521  1.1448419  -5.3883104  -3.9102452   0.09650555]\n",
      "   [-0.18614332  0.65958387  1.6296635   2.2752664   4.8744435 ]\n",
      "   [ 2.38591    -0.22541776  3.288232   -4.2391543  -1.4026946 ]\n",
      "   [ 0.82496303  1.7102693  -3.2459726   3.2460587   1.7087309 ]\n",
      "   [ 0.8088478   3.6953452   3.4905758  -2.112783   -2.713672  ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy results\")\n",
    "conv_results_numpy = conv_numpy_2(input_image, conv_weights, stride, pad=1)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04d19d2-a866-44a1-9cbe-09606e5241dd",
   "metadata": {},
   "source": [
    "### Define Numpy Convolution (Input and Output Layers)\n",
    "Define a function that uses Numpy functions to perform convolution for a random image, with the incorporation of the input layers of the image and the output layer of the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6af50135-7354-4a3f-a83d-da0db7d31e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_numpy_3(image, weights, stride=1, pad=1):\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Determine sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Determine size of output arrays\n",
    "    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n",
    "    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n",
    "\n",
    "    # Define an array structure for the output of the CNN\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    # For the location of each pixel on the final image\n",
    "    for c_y in range(imageHeightOut):\n",
    "      for c_x in range(imageWidthOut):\n",
    "        # For each input layer and output layer\n",
    "        for c_channel_out in range(channelsOut):\n",
    "          for c_channel_in in range(channelsIn):\n",
    "            # For the location of each pixel on the kernel\n",
    "            for c_kernel_y in range(kernelHeight):\n",
    "              for c_kernel_x in range(kernelWidth):\n",
    "                  # Compute the value of the pixel and the value of the corresponding kernel for each input and output layer\n",
    "                  this_pixel_value = image[0, c_channel_in, c_kernel_y+c_y, c_kernel_x+c_x]\n",
    "                  this_weight = weights[c_channel_out, c_channel_in, c_kernel_y, c_kernel_x]\n",
    "\n",
    "                  # Multiply the value of the kernel by the value at the location of the pixel to compute the activation map\n",
    "                  out[0, c_channel_out, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6ac997-e683-40de-959c-2b37180f6fb7",
   "metadata": {},
   "source": [
    "### Initialize Hyperparameters\n",
    "Initialize the hyperparameters for the convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fcef9991-c71b-4ead-897f-f67c5ba1ba5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n_batch = 1\n",
    "image_height = 4\n",
    "image_width = 6\n",
    "channels_in = 5\n",
    "kernel_size = 3\n",
    "channels_out = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3656ac5d-c0cf-4427-be42-11c326abb776",
   "metadata": {},
   "source": [
    "### Define Input\n",
    "Define a random image as the input for the convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce7b70df-86ad-423b-b672-f82faa5aac06",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985f3cab-8442-4865-9f9b-05dc98fbf925",
   "metadata": {},
   "source": [
    "### Initialize Kernel Weights\n",
    "Initialize the weights of the kernel for the convolution function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48b03e34-26a7-4bf6-ab28-2eeb442f73b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c246e8f-94c9-48d1-bed5-9654304e4990",
   "metadata": {},
   "source": [
    "### Convolution (PyTorch)\n",
    "Perform PyTorch's convolution function on the input image and print the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "86b70af3-cedb-4ddf-b540-5a6d6081a83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[ -0.78493005   5.46317843  -2.48025844   5.02562432  -3.59404407\n",
      "      7.78488108]\n",
      "   [ -6.74353604   2.53411115  -0.66394352   7.14885746  -9.83852552\n",
      "      7.8488439 ]\n",
      "   [ -4.79449808  14.0742739   -1.06040823   2.70604367 -10.18183894\n",
      "      2.0036554 ]\n",
      "   [  1.80853737   0.28671588   4.64779395  -1.83962197   3.25877536\n",
      "      1.0733081 ]]\n",
      "\n",
      "  [[  4.14990184   5.37204436   1.69949782   0.49957395   0.5894419\n",
      "      4.36072584]\n",
      "   [ -4.12345821   5.1360658    4.67700784  -3.89519639  -4.99028029\n",
      "      2.54604406]\n",
      "   [  3.99092569   5.76840128  -2.31524793   8.47292739   1.7520073\n",
      "      2.76562704]\n",
      "   [  1.52850472   0.3179325   11.51848119  -5.44439849  -2.29293586\n",
      "      1.26966775]]]]\n"
     ]
    }
   ],
   "source": [
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f213b1-2591-4e8e-93ae-e5d0233d8823",
   "metadata": {},
   "source": [
    "### Convolution (Numpy)\n",
    "Perform Numpy's convolution function on the input image and print the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f31c3d67-92e5-4211-a6a3-5b4dd4231d69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy results\n",
      "[[[[ -0.78493017   5.4631777   -2.4802582    5.025625    -3.594044\n",
      "      7.784882  ]\n",
      "   [ -6.7435346    2.5341108   -0.6639434    7.1488576   -9.838525\n",
      "      7.8488436 ]\n",
      "   [ -4.794498    14.074275    -1.0604087    2.7060435  -10.181838\n",
      "      2.003656  ]\n",
      "   [  1.8085374    0.2867157    4.647794    -1.8396223    3.2587752\n",
      "      1.0733079 ]]\n",
      "\n",
      "  [[  4.149902     5.3720446    1.6994978    0.4995738    0.5894427\n",
      "      4.360726  ]\n",
      "   [ -4.123459     5.136065     4.6770077   -3.8951955   -4.990279\n",
      "      2.546044  ]\n",
      "   [  3.9909263    5.768401    -2.3152485    8.472927     1.7520071\n",
      "      2.765627  ]\n",
      "   [  1.5285047    0.317932    11.518481    -5.4443984   -2.2929363\n",
      "      1.2696676 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy results\")\n",
    "conv_results_numpy = conv_numpy_3(input_image, conv_weights, stride=1, pad=1)\n",
    "print(conv_results_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100448f3-0057-45f9-bcf6-d18857f554e4",
   "metadata": {},
   "source": [
    "### Define Numpy Convolution (Stride + Input and Output Layer)\n",
    "Define a function that uses Numpy functions to perform convolution for a random image, with the incorporation of a stride for the kernel, the input layers of the image, and the output layers of the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "83374fed-91ba-41fc-9058-2802f74611fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_numpy_4(image, weights, stride=1, pad=1):\n",
    "    # Perform zero padding\n",
    "    if pad != 0:\n",
    "        image = np.pad(image, ((0, 0), (0 ,0), (pad, pad), (pad, pad)),'constant')\n",
    "\n",
    "    # Determine sizes of image array and kernel weights\n",
    "    batchSize,  channelsIn, imageHeightIn, imageWidthIn = image.shape\n",
    "    channelsOut, channelsIn, kernelHeight, kernelWidth = weights.shape\n",
    "\n",
    "    # Deterime size of output arrays\n",
    "    imageHeightOut = np.floor(1 + (imageHeightIn - kernelHeight) / stride).astype(int)\n",
    "    imageWidthOut = np.floor(1 + (imageWidthIn - kernelWidth) / stride).astype(int)\n",
    "\n",
    "    # Define an array structure for the output of the CNN\n",
    "    out = np.zeros((batchSize, channelsOut, imageHeightOut, imageWidthOut), dtype=np.float32)\n",
    "\n",
    "    # For each iamge\n",
    "    for c_batch in range(batchSize):\n",
    "      # For the location of each pixel on the final image\n",
    "      for c_y in range(imageHeightOut):\n",
    "        for c_x in range(imageWidthOut):\n",
    "          # For each input and output layer\n",
    "          for c_channel_out in range(channelsOut):\n",
    "            for c_channel_in in range(channelsIn):\n",
    "              # For the location of each pixel on the kernel\n",
    "              for c_kernel_y in range(kernelHeight):\n",
    "                for c_kernel_x in range(kernelWidth):\n",
    "                    # Compute the value of the pixel and the value of the corresopnding kernel weights for each input and output layer\n",
    "                    # Incorporate stride towards the location of the pixel\n",
    "                    this_pixel_value = image[c_batch, c_channel_in, c_kernel_y+c_y*stride, c_kernel_x+c_x*stride]\n",
    "                    this_weight = weights[c_channel_out, c_channel_in, c_kernel_y, c_kernel_x]\n",
    "\n",
    "                    # Multiply the value of the kernel by the value at the location of the pixel to compute the activation map\n",
    "                    out[c_batch, c_channel_out, c_y, c_x] += np.sum(this_pixel_value * this_weight)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15101536-74a4-43d8-94a2-d4623b192ead",
   "metadata": {},
   "source": [
    "### Initialize Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b20a1a97-8678-4d56-9ea2-1a89849de0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "n_batch = 2\n",
    "image_height = 4\n",
    "image_width = 6\n",
    "channels_in = 5\n",
    "kernel_size = 3\n",
    "channels_out = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a07ed6-3638-4834-9df2-03960836fb6a",
   "metadata": {},
   "source": [
    "### Define Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1061d7ce-971f-4cd7-88dd-c2e4ff858a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image= np.random.normal(size=(n_batch, channels_in, image_height, image_width))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c51a1-e1c3-4604-b924-ff37c7a0fab7",
   "metadata": {},
   "source": [
    "### Initialize Kernel Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84c0be9e-414b-4ff4-8af5-e5608861a5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_weights = np.random.normal(size=(channels_out, channels_in, kernel_size, kernel_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e137d8ce-2da2-45fb-9b99-49ada2167df3",
   "metadata": {},
   "source": [
    "### Convolution (PyTorch)\n",
    "Perform PyTorch's convolution function on the input image and print the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28b607c4-ce34-422b-8936-e75335378ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Results\n",
      "[[[[ -3.63266998  -1.64414063   0.16871541  -1.16683534  -3.86470503\n",
      "      6.04548497]\n",
      "   [ -9.00441048   7.30303198   4.41414413   0.36094645  -6.73911902\n",
      "      3.93877819]\n",
      "   [ -1.39066168  13.50223385   3.80719001  -9.37925647   3.99065754\n",
      "      5.44193873]\n",
      "   [  2.80529354   6.87386967  -9.28708597  -4.4677558   -1.50120554\n",
      "      4.60699744]]\n",
      "\n",
      "  [[  1.93991531  -1.40994827   2.39733412  -0.23498018  -0.39417446\n",
      "     -1.48273797]\n",
      "   [  5.04926785  -3.33537397  -7.59638391  -1.58618293   3.04942231\n",
      "     -1.85714215]\n",
      "   [  3.51356752   0.47452556  -1.95244809  -1.29143814  -0.58875724\n",
      "     -0.94794943]\n",
      "   [  6.52359837  -0.01988546  -3.29757656  -1.24783696   3.24882183\n",
      "     -2.67951281]]]\n",
      "\n",
      "\n",
      " [[[  4.15358547  -4.76441146  11.63518341   0.50610631  -4.01175338\n",
      "     -2.08113863]\n",
      "   [ -1.12514613  -0.67652481  16.74850235  -7.03000422  -5.97797666\n",
      "     -2.6288367 ]\n",
      "   [  0.77808623  -3.98359269 -10.28402713   1.57539725  -8.88848701\n",
      "      1.16275197]\n",
      "   [  0.55557572  -2.29044411   1.40686035  -3.08761914   2.22661083\n",
      "     -5.40255425]]\n",
      "\n",
      "  [[  1.04788107   4.32188131  -0.90122505  -5.81995714   3.99801237\n",
      "      2.28082342]\n",
      "   [ -1.31322095   8.40917456  -0.09999107  14.62453593   1.22250982\n",
      "     -3.5717874 ]\n",
      "   [  1.41146787   1.61652106  -4.07788023  -8.10720678   3.70462332\n",
      "      0.22885219]\n",
      "   [ -3.53970801  -5.2918022   -5.61863727  -4.03887141  -4.04816689\n",
      "     -3.44561124]]]]\n"
     ]
    }
   ],
   "source": [
    "conv_results_pytorch = conv_pytorch(input_image, conv_weights, stride=1, pad=1)\n",
    "print(\"PyTorch Results\")\n",
    "print(conv_results_pytorch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66d9da0-9f8a-4e45-b6c3-9c327fdb2bd0",
   "metadata": {},
   "source": [
    "### Convolution (Numpy)\n",
    "Perform Numpy's convolution function on the input image and print the feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e70b17f2-77d7-47f2-88d3-19f32b9bded3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy results\n",
      "[[[[ -3.63267     -1.6441412    0.16871582  -1.1668352   -3.8647041\n",
      "      6.0454845 ]\n",
      "   [ -9.004409     7.3030324    4.414145     0.36094612  -6.7391195\n",
      "      3.9387782 ]\n",
      "   [ -1.3906618   13.5022335    3.80719     -9.379255     3.9906573\n",
      "      5.4419394 ]\n",
      "   [  2.8052933    6.873869    -9.287086    -4.4677553   -1.5012054\n",
      "      4.606998  ]]\n",
      "\n",
      "  [[  1.9399152   -1.4099485    2.3973339   -0.23498023  -0.3941749\n",
      "     -1.4827379 ]\n",
      "   [  5.0492682   -3.3353736   -7.5963855   -1.5861826    3.0494225\n",
      "     -1.8571423 ]\n",
      "   [  3.5135674    0.47452566  -1.9524485   -1.2914382   -0.58875686\n",
      "     -0.9479495 ]\n",
      "   [  6.5235977   -0.0198854   -3.297577    -1.2478366    3.2488215\n",
      "     -2.6795127 ]]]\n",
      "\n",
      "\n",
      " [[[  4.153585    -4.7644105   11.635186     0.5061073   -4.0117536\n",
      "     -2.0811388 ]\n",
      "   [ -1.1251465   -0.67652464  16.7485      -7.0300035   -5.9779778\n",
      "     -2.6288366 ]\n",
      "   [  0.77808625  -3.9835927  -10.284027     1.5753975   -8.888488\n",
      "      1.1627522 ]\n",
      "   [  0.5555758   -2.290444     1.4068604   -3.0876188    2.2266104\n",
      "     -5.402554  ]]\n",
      "\n",
      "  [[  1.047881     4.3218813   -0.90122634  -5.819957     3.998013\n",
      "      2.2808232 ]\n",
      "   [ -1.3132199    8.409174    -0.09999097  14.6245365    1.2225106\n",
      "     -3.5717874 ]\n",
      "   [  1.411468     1.6165196   -4.077881    -8.107207     3.7046232\n",
      "      0.22885232]\n",
      "   [ -3.5397081   -5.291803    -5.6186376   -4.0388722   -4.0481668\n",
      "     -3.4456115 ]]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Numpy results\")\n",
    "conv_results_numpy = conv_numpy_4(input_image, conv_weights, stride=1, pad=1)\n",
    "print(conv_results_numpy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RDKit)",
   "language": "python",
   "name": "rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
