{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec99eea-ca1c-4d86-ab64-b9f077983e73",
   "metadata": {},
   "source": [
    "# Regularization \n",
    "This notebook aims to help gain a mathematical understanding of implicit and explicit regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e32682-abf4-4a59-b58d-d17fd02ff3d4",
   "metadata": {},
   "source": [
    "## Explicit Regularization \n",
    "For explicit regularization, a regularization term is added to improve the generalization of a neural network model by penalizing certain parameter values that overfit the training data. The regularization term can be added to the loss function, which would be expressed as:\n",
    "\n",
    "$$\n",
    "\\hat{\\phi}\n",
    "= \\arg\\min_{\\phi}\n",
    "\\left[\n",
    "\\sum_{i=1}^{I} \\ell_i[\\mathbf{x}_i, \\mathbf{y}_i]\n",
    "+ \\lambda \\cdot g[\\phi]\n",
    "\\right]$$\n",
    "\n",
    "Where:\n",
    "-  $g[\\phi]$ represents the regularization term, where parameters that are less preferred by the model causes the regularization term to output a higher value\n",
    "\n",
    "-  $\\lambda$ represents a scalar that controls the effect that the regularization term ($g[\\phi]$) has on the loss function\n",
    "\n",
    "In addition, the regularization term can also be added to the maximum likelihood criterion, which would be expressed as: \n",
    "\n",
    "$$\n",
    "\\hat{\\phi} = \\arg\\max_{\\phi}\n",
    "\\left[\n",
    "\\prod_{i=1}^{I}\n",
    "\\Pr(y_i \\mid \\mathbf{x}_i, \\phi)\\,\\Pr(\\phi)\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "Where: \n",
    "- $\\Pr(\\phi)$ is the regularization term, which expressess the model's assumptions on the distribution of the parameters prior to observing the data\n",
    "\n",
    "Even though regularization terms penalize certain parameter values, the following equations don't show a way to manipulate the regularization term to penalize parameter values that overfit the trainnig data. By using L2 regularization, we are able to penalize parameters with large weight values. L2 regularization is represented as:\n",
    "\n",
    "$$\n",
    "\\hat{\\phi}\n",
    "= \\arg\\min_{\\phi}\n",
    "\\left[\n",
    "\\sum_{i=1}^{I} \\ell_i[\\mathbf{x}_i, \\mathbf{y}_i]\n",
    "\\;+\\;\n",
    "\\lambda \\sum_{j} \\phi_j^{2}\n",
    "\\right].\n",
    "$$\n",
    "\n",
    "Where: \n",
    "- $\\;\\lambda \\sum_{j} \\phi_j^{2}$ is the L2 norm (L2 regularization term), which represents the magnitude of the weights. Therefore higher values of weights corresponds to an increase in loss and a penalizing in that specific set of parameter values.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c845fd86-92d5-414e-a749-a6466bb62875",
   "metadata": {},
   "source": [
    "## Implicit Regularization \n",
    "For implicit regularization, the stochastic gradient descent step or the gradient descent step automatically favors certain parameter values over others without the manual addition of a regularization term \n",
    "\n",
    "A favoring in certain parameter values is shown because when a parameter is updated through either the stochastic gradient descent step or the gradient descent step, the loss function is modified. For gradient descent steps, the modified loss function is represented as: \n",
    "\n",
    "$$\n",
    "\\tilde{L}_{GD}[\\phi]\n",
    "= L[\\phi] + \\frac{\\alpha}{4} \\left\\lVert \\frac{\\partial L}{\\partial \\phi} \\right\\rVert^2\n",
    "$$ \n",
    "\n",
    "Where: \n",
    "- $\\frac{\\alpha}{4} \\left\\lVert \\frac{\\partial L}{\\partial \\phi} \\right\\rVert^2$ represents the regularization term.\n",
    "\n",
    "$\\frac{\\alpha}{4} \\left\\lVert \\frac{\\partial L}{\\partial \\phi} \\right\\rVert^2$ is dependent on the value of the gradient ($\\frac{\\partial L}{\\partial \\phi}$). The value of the gradient is dependent on the value of the parameters, where higher parameter values results in larger gradients and vice versa. Therefore by the addition of this regularization term, it favors small parameter values over large parameter values\n",
    "\n",
    "For stochastic gradient descent steps, the modified loss function is represented as:\n",
    "\n",
    "$$\n",
    "\\tilde{L}_{SGD}[\\phi]\n",
    "=\n",
    "\\tilde{L}_{GD}[\\phi]\n",
    "+\n",
    "\\frac{\\alpha}{4B}\n",
    "\\sum_{b=1}^{B}\n",
    "\\left\\lVert\n",
    "\\frac{\\partial L_b}{\\partial \\phi}\n",
    "-\n",
    "\\frac{\\partial L}{\\partial \\phi}\n",
    "\\right\\rVert^2\n",
    "$$\n",
    "\n",
    "Where: \n",
    "- $\\frac{\\partial L}{\\partial \\phi}$ is the gradient of the loss function for the entire dataset\n",
    "\n",
    "- $\\frac{\\partial L_b}{\\partial \\phi}$ is the gradient of the loss function for each batch of dataset\n",
    "\n",
    "Because the regularization term ($\\frac{\\alpha}{4B}\\sum_{b=1}^{B}\\left\\lVert\\frac{\\partial L_b}{\\partial \\phi}-\\frac{\\partial L}{\\partial \\phi}\\right\\rVert^2$) takes the difference between $\\frac{\\partial L}{\\partial \\phi}$ and $\\frac{\\partial L_b}{\\partial \\phi}$, the stochastic gradient descent step favors values of parameters that results in a small batch variance and a small difference between the batch gradient and the overall gradient."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RDKit)",
   "language": "python",
   "name": "rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
