{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5889d2e5-202f-4a0b-9c46-d9ac9147ed96",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "This notebook aims to help gain a better understanding of tokenization by defining a tokenization function that decomposes the input text into a vocabulary of words, which is then converted into tokens. In addition, the tokens are refinied by joining the token pair with the highest frequency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b2b02b-69dc-4635-ac5f-cd55f5051f82",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f645d3dc-f681-49ec-ac06-e3c8ad663736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, collections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add52dda-f830-4cf8-9ed4-29bc4c2c8af7",
   "metadata": {},
   "source": [
    "### Define Input Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6024105b-7495-4984-83aa-82e88b0b2e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"a sailor went to sea sea sea \"+\\\n",
    "                  \"to see what he could see see see \"+\\\n",
    "                  \"but all that he could see see see \"+\\\n",
    "                  \"was the bottom of the deep blue sea sea sea\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8c28b1-abfd-4cb8-b37d-5c2a0a4b3d1a",
   "metadata": {},
   "source": [
    "### Define Vocabulary Function\n",
    "Define a function that separates the input text into individual words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21141689-42c9-456b-b657-ad5f21da33c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vocabulary(text):\n",
    "  vocab = collections.defaultdict(int)\n",
    "  words = text.strip().split()\n",
    "  for word in words:\n",
    "      vocab[' '.join(list(word)) + ' '] += 1\n",
    "  return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5011ae-8c6b-48a1-a534-a6ee5787110b",
   "metadata": {},
   "source": [
    "### Execute initialize_vocabulary\n",
    "Execute initialize_vocabulary to compute a list of vocabulary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a34881-6236-4aa2-900c-f6e1507ded15",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = initialize_vocabulary(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a68247f-3d08-4b86-949b-e78fbf13add8",
   "metadata": {},
   "source": [
    "### Print Vocabulary Words and Size\n",
    "Print all the words in the vocabulary and the size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8329a958-38ca-4760-9b39-3e4b7d3eb80a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: defaultdict(<class 'int'>, {'a ': 1, 's a i l o r ': 1, 'w e n t ': 1, 't o ': 2, 's e a ': 6, 's e e ': 7, 'w h a t ': 1, 'h e ': 2, 'c o u l d ': 2, 'b u t ': 1, 'a l l ': 1, 't h a t ': 1, 'w a s ': 1, 't h e ': 2, 'b o t t o m ': 1, 'o f ': 1, 'd e e p ': 1, 'b l u e ': 1})\n",
      "Size of vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary: {}'.format(vocab))\n",
    "print('Size of vocabulary: {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f90697-c823-473a-af03-be63c59432ff",
   "metadata": {},
   "source": [
    "### Define Token Function\n",
    "Define a function that computes tokens from the individual words and computes the frequency of each token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "646fdaeb-d93c-4348-9d20-e7ad7dc632c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_and_frequencies(vocab):\n",
    "  tokens = collections.defaultdict(int)\n",
    "  for word, freq in vocab.items():\n",
    "      word_tokens = word.split()\n",
    "      for token in word_tokens:\n",
    "          tokens[token] += freq\n",
    "  return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "331e8011-2d99-41c4-91d5-e3f939d0c631",
   "metadata": {},
   "source": [
    "### Execute get_tokens_and_frequencies\n",
    "Execute get_tokens_and_frequencies to compute a list of tokens and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9d489a9-5182-4335-806a-2be9e71046f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = get_tokens_and_frequencies(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa669d8-01b0-4dc4-882f-95b099c47f4a",
   "metadata": {},
   "source": [
    "### Print Tokens and Frequencies\n",
    "Print a list of all the computed tokens as well as each of their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cb8dd7b-af7a-4429-85b4-1956a5a20aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: defaultdict(<class 'int'>, {'a': 12, 's': 15, 'i': 1, 'l': 6, 'o': 8, 'r': 1, 'w': 3, 'e': 28, 'n': 1, 't': 11, 'h': 6, 'c': 2, 'u': 4, 'd': 3, 'b': 3, 'm': 1, 'f': 1, 'p': 1})\n",
      "Number of tokens: 18\n"
     ]
    }
   ],
   "source": [
    "print('Tokens: {}'.format(tokens))\n",
    "print('Number of tokens: {}'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485be949-5f6f-4e0a-a292-06ae284c1f9d",
   "metadata": {},
   "source": [
    "### Define Pair Function\n",
    "Define a function that computes all the letter pairs in the vocabulary and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45b411cd-b29f-4435-8af9-bf1fe5f502fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs_and_counts(vocab):\n",
    "    pairs = collections.defaultdict(int)\n",
    "    for word, freq in vocab.items():\n",
    "        symbols = word.split()\n",
    "        for i in range(len(symbols)-1):\n",
    "            pairs[symbols[i],symbols[i+1]] += freq\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e59627-613d-45d1-8f0a-2166943b7194",
   "metadata": {},
   "source": [
    "### Execute get_pairs_and_counts\n",
    "Execute get_pairs_and_counts to compute all the letter pairs and each of their frequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfb9f521-54b3-4ace-a448-baff0c360b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = get_pairs_and_counts(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bfeaff-28ab-4df8-ba21-9096249e8f2a",
   "metadata": {},
   "source": [
    "### Print Letter Pairs and Frequencies\n",
    "Print all the letter pairs and each of their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a570f55b-750c-429c-883d-6cec1a551847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairs: defaultdict(<class 'int'>, {('s', 'a'): 1, ('a', 'i'): 1, ('i', 'l'): 1, ('l', 'o'): 1, ('o', 'r'): 1, ('w', 'e'): 1, ('e', 'n'): 1, ('n', 't'): 1, ('t', 'o'): 3, ('s', 'e'): 13, ('e', 'a'): 6, ('e', 'e'): 8, ('w', 'h'): 1, ('h', 'a'): 2, ('a', 't'): 2, ('h', 'e'): 4, ('c', 'o'): 2, ('o', 'u'): 2, ('u', 'l'): 2, ('l', 'd'): 2, ('b', 'u'): 1, ('u', 't'): 1, ('a', 'l'): 1, ('l', 'l'): 1, ('t', 'h'): 3, ('w', 'a'): 1, ('a', 's'): 1, ('b', 'o'): 1, ('o', 't'): 1, ('t', 't'): 1, ('o', 'm'): 1, ('o', 'f'): 1, ('d', 'e'): 1, ('e', 'p'): 1, ('b', 'l'): 1, ('l', 'u'): 1, ('u', 'e'): 1})\n",
      "Number of distinct pairs: 37\n"
     ]
    }
   ],
   "source": [
    "print('Pairs: {}'.format(pairs))\n",
    "print('Number of distinct pairs: {}'.format(len(pairs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d448eade-d82d-400b-bc95-9fd9edbffcdf",
   "metadata": {},
   "source": [
    "### Compute and Print Most Frequent Letter Pair\n",
    "Compute and print the most frequent letter pair out of all the letter pairs that were computed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d845236-d43c-44af-b282-9a18a7b82cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent pair: ('s', 'e')\n"
     ]
    }
   ],
   "source": [
    "most_frequent_pair = max(pairs, key=pairs.get)\n",
    "print('Most frequent pair: {}'.format(most_frequent_pair))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a729f2e4-e80f-4ae2-b109-6f559ccb78b5",
   "metadata": {},
   "source": [
    "### Define Pair Merge Function\n",
    "Define a function that merges letter pairs in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cfd5a23-c91c-478e-8941-961f6135cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pair_in_vocabulary(pair, vocab_in):\n",
    "    vocab_out = {}\n",
    "    bigram = re.escape(' '.join(pair))\n",
    "    p = re.compile(r'(?<!\\S)' + bigram + r'(?!\\S)')\n",
    "    for word in vocab_in:\n",
    "        word_out = p.sub(''.join(pair), word)\n",
    "        vocab_out[word_out] = vocab_in[word]\n",
    "    return vocab_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f74e3-a5c9-4d77-b685-ec8806fd34d3",
   "metadata": {},
   "source": [
    "### Execute merge_pair_in_vocabulary \n",
    "Execute merge_pair_in_vocabulary to merge the most frequent letter pairs and reupdate the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb35eea-aecb-4503-900e-8a209c336d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = merge_pair_in_vocabulary(most_frequent_pair, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5d8084-7689-470f-accf-4e3c42db9091",
   "metadata": {},
   "source": [
    "### Print Vocabulary and Size\n",
    "Print the newly updated vocabulary and the vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "011326ee-e768-4909-9e28-65792b0b5b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary: {'a ': 1, 's a i l o r ': 1, 'w e n t ': 1, 't o ': 2, 'se a ': 6, 'se e ': 7, 'w h a t ': 1, 'h e ': 2, 'c o u l d ': 2, 'b u t ': 1, 'a l l ': 1, 't h a t ': 1, 'w a s ': 1, 't h e ': 2, 'b o t t o m ': 1, 'o f ': 1, 'd e e p ': 1, 'b l u e ': 1}\n",
      "Size of vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary: {}'.format(vocab))\n",
    "print('Size of vocabulary: {}'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd22073-76fd-4bc6-b2c5-95bae9b09615",
   "metadata": {},
   "source": [
    "### Execute get_tokens_and_frequencies\n",
    "Execute get_tokens_and_frequencies to get the new tokens and its frequencies from the new vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c518d08f-c2ac-4f10-a503-3945f3fc106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = get_tokens_and_frequencies(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b295015-df49-4ecb-89a5-73d82d4b9493",
   "metadata": {},
   "source": [
    "### Print Tokens and Frequencies\n",
    "Print all the tokens and each of the token's frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbf33e52-0bce-44b9-9cd0-ffca9ba0770e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: defaultdict(<class 'int'>, {'a': 12, 's': 2, 'i': 1, 'l': 6, 'o': 8, 'r': 1, 'w': 3, 'e': 15, 'n': 1, 't': 11, 'se': 13, 'h': 6, 'c': 2, 'u': 4, 'd': 3, 'b': 3, 'm': 1, 'f': 1, 'p': 1})\n",
      "Number of tokens: 19\n"
     ]
    }
   ],
   "source": [
    "print('Tokens: {}'.format(tokens))\n",
    "print('Number of tokens: {}'.format(len(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a5943b-a40f-4884-a51f-8dbdd962c39c",
   "metadata": {},
   "source": [
    "### Define Tokenization Function\n",
    "Define a tokenization function, which uses the previously defined function to convert input texts into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1dccde9-f544-482f-8214-905e53fdc299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, num_merges):\n",
    "  # Initialize the vocabulary from the input text\n",
    "  vocab = initialize_vocabulary(text)\n",
    "\n",
    "  # For each pair merge in a defined amount of pair merges\n",
    "  for i in range(num_merges):\n",
    "    # Compute the tokens and their frequency in the vocabulary\n",
    "    tokens = get_tokens_and_frequencies(vocab)\n",
    "\n",
    "    # Compute the pairs of adjacent tokens and their frequencies\n",
    "    pairs = get_pairs_and_counts(vocab)\n",
    "\n",
    "    # Find the most frequent pair\n",
    "    most_frequent_pair = max(pairs, key=pairs.get)\n",
    "    print('Most frequent pair: {}'.format(most_frequent_pair))\n",
    "\n",
    "    # Merge the most frequent pair in the vocabulary\n",
    "    vocab = merge_pair_in_vocabulary(most_frequent_pair, vocab)\n",
    "\n",
    "  # Compute the tokens and their frequency in the vocabulary\n",
    "  tokens = get_tokens_and_frequencies(vocab)\n",
    "\n",
    "  return tokens, vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9114109a-81b7-47c7-ae77-50710349310c",
   "metadata": {},
   "source": [
    "### Tokenize Input Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13db856f-f8d5-43a5-bc88-39bcd4d200e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent pair: ('s', 'e')\n",
      "Most frequent pair: ('se', 'e')\n",
      "Most frequent pair: ('se', 'a')\n",
      "Most frequent pair: ('h', 'e')\n",
      "Most frequent pair: ('t', 'o')\n",
      "Most frequent pair: ('h', 'a')\n",
      "Most frequent pair: ('ha', 't')\n",
      "Most frequent pair: ('c', 'o')\n",
      "Most frequent pair: ('co', 'u')\n",
      "Most frequent pair: ('cou', 'l')\n",
      "Most frequent pair: ('coul', 'd')\n",
      "Most frequent pair: ('t', 'he')\n",
      "Most frequent pair: ('s', 'a')\n",
      "Most frequent pair: ('sa', 'i')\n",
      "Most frequent pair: ('sai', 'l')\n",
      "Most frequent pair: ('sail', 'o')\n",
      "Most frequent pair: ('sailo', 'r')\n",
      "Most frequent pair: ('w', 'e')\n",
      "Most frequent pair: ('we', 'n')\n",
      "Most frequent pair: ('wen', 't')\n",
      "Most frequent pair: ('w', 'hat')\n",
      "Most frequent pair: ('b', 'u')\n"
     ]
    }
   ],
   "source": [
    "tokens, vocab = tokenize(text, num_merges=22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1333983-afa9-4956-b0fb-0cc50fe49c0f",
   "metadata": {},
   "source": [
    "### Print Tokens, Frequency of Tokens, Vocabulary, and Size of Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c253bc0d-cecf-470b-ad0f-6f65dc4f05f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: defaultdict(<class 'int'>, {'a': 3, 'sailor': 1, 'went': 1, 'to': 3, 'sea': 6, 'see': 7, 'what': 1, 'he': 2, 'could': 2, 'bu': 1, 't': 3, 'l': 3, 'hat': 1, 'w': 1, 's': 1, 'the': 2, 'b': 2, 'o': 2, 'm': 1, 'f': 1, 'd': 1, 'e': 3, 'p': 1, 'u': 1})\n",
      "Number of tokens: 24\n",
      "Vocabulary: {'a ': 1, 'sailor ': 1, 'went ': 1, 'to ': 2, 'sea ': 6, 'see ': 7, 'what ': 1, 'he ': 2, 'could ': 2, 'bu t ': 1, 'a l l ': 1, 't hat ': 1, 'w a s ': 1, 'the ': 2, 'b o t to m ': 1, 'o f ': 1, 'd e e p ': 1, 'b l u e ': 1}\n",
      "Size of vocabulary: 18\n"
     ]
    }
   ],
   "source": [
    "print('Tokens: {}'.format(tokens))\n",
    "print('Number of tokens: {}'.format(len(tokens)))\n",
    "print('Vocabulary: {}'.format(vocab))\n",
    "print('Size of vocabulary: {}'.format(len(vocab)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RDKit)",
   "language": "python",
   "name": "rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
