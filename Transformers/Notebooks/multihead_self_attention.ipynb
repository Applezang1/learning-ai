{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7de6655-b490-47fd-9ebb-bbeeb03231b5",
   "metadata": {},
   "source": [
    "# Multihead Self Attention\n",
    "This notebook aims to help develop a better understanding of the multihead self attention mechanism by defining a multihead self attention mechanism and using it to compute an array of output values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76372f4a-a463-4f61-a3ca-518975ae9d19",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43762af8-1c76-4fcf-b870-b348c480c175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b41b922-b358-4f2c-92fe-5c090bbe67b1",
   "metadata": {},
   "source": [
    "## Initialize Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c2937c-b8d9-4fd4-810b-6f910807c2cc",
   "metadata": {},
   "source": [
    "### Define the Number of Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8025557-d6c0-4fab-8c0d-8d0714cdce2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fdf62a-2168-4935-940f-c99fe9bd4fce",
   "metadata": {},
   "source": [
    "### Define the Number of Dimensions of Each Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a6687c9-b396-42c8-aadf-721d165f1cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e29b57-3b6c-44ed-92a8-0d40900a18b2",
   "metadata": {},
   "source": [
    "### Initialize Input Data\n",
    "Initialize an empty list as the input data for the multihead self attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "647cbbff-023d-4b56-96b7-640ed3f009b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "X = np.random.normal(size=(D,N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da932a-6763-4139-90df-9c69d2246e9d",
   "metadata": {},
   "source": [
    "### Define the Number of Heads\n",
    "Define the number of heads for the multi-head self-attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b6b47dc-3b70-49fb-9f15-2bd97e7893d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46b7845-ff30-4a01-baa7-417b96ecf3b5",
   "metadata": {},
   "source": [
    "### Define Dimensions of QKV (Query, Key, Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718b51f4-32ac-4e28-a470-9902407389f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "H_D = int(D/H)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e77289f-5a74-412a-b4c3-498991f440d8",
   "metadata": {},
   "source": [
    "### Initialize Parameter Value (first head)\n",
    "Initialize random values for the parameter of the first head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de8a38b-dfc6-41a4-99b5-0b63dfe42ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "omega_q1 = np.random.normal(size=(H_D,D))\n",
    "omega_k1 = np.random.normal(size=(H_D,D))\n",
    "omega_v1 = np.random.normal(size=(H_D,D))\n",
    "beta_q1 = np.random.normal(size=(H_D,1))\n",
    "beta_k1 = np.random.normal(size=(H_D,1))\n",
    "beta_v1 = np.random.normal(size=(H_D,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30cd183a-3dbc-4409-a292-7b7e21f75b9b",
   "metadata": {},
   "source": [
    "### Initialize Parameter Value (second head)\n",
    "Initialize random values for the parameter of the second head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d256d3-2588-4b5f-bf50-95ced2dd31b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_q2 = np.random.normal(size=(H_D,D))\n",
    "omega_k2 = np.random.normal(size=(H_D,D))\n",
    "omega_v2 = np.random.normal(size=(H_D,D))\n",
    "beta_q2 = np.random.normal(size=(H_D,1))\n",
    "beta_k2 = np.random.normal(size=(H_D,1))\n",
    "beta_v2 = np.random.normal(size=(H_D,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e78a4-5f88-42bc-8f50-137761d3d6a6",
   "metadata": {},
   "source": [
    "### Initialize Model Weights\n",
    "Initialize random values for the final weight of the multihead self attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce2011c-f4c9-4528-a533-05b480bd3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_c = np.random.normal(size=(D,D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1056c548-b135-45a3-ba2d-6b8d49dc1029",
   "metadata": {},
   "source": [
    "### Define Softmax Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c46ae46-65b8-4fe9-b3ea-4861c0e1396d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_cols(data_in):\n",
    "  # Exponentiate all of the values (numerator)\n",
    "  exp_values = np.exp(data_in) \n",
    "  # Sum the exponentiated values over all columns (denominator)\n",
    "  denom = np.sum(exp_values, axis = 0)\n",
    "  # Compute softmax function\n",
    "  softmax = exp_values / denom\n",
    "\n",
    "  return softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5523ea38-b2f2-4350-a99f-d50c42e662ee",
   "metadata": {},
   "source": [
    "### Define Multihead Scaled Self Attention Function\n",
    "Define a function that passes input values through the multihead scaled self attention mechanism in matrix form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c2fb29e-0738-412a-bd17-b518f6eb1ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def multihead_scaled_self_attention(X,omega_v1, omega_q1, omega_k1, beta_v1, beta_q1, beta_k1, omega_v2, omega_q2, omega_k2, beta_v2, beta_q2, beta_k2, omega_c):\n",
    "  # Define array structure for the output data\n",
    "  X_prime = np.zeros_like(X) \n",
    "\n",
    "  # Compute QKV values for the first heaad\n",
    "  all_values_1 = beta_v1 + (omega_v1 @ X)\n",
    "  all_query_1 = beta_q1 + (omega_q1 @ X)\n",
    "  all_key_1 = beta_k1 + (omega_k1 @ X)\n",
    "\n",
    "  # Compute QKV values for the second head\n",
    "  all_values_2 = beta_v2 + (omega_v2 @ X) \n",
    "  all_query_2 = beta_q2 + (omega_q2 @ X) \n",
    "  all_key_2 = beta_k2 + (omega_k2 @ X) \n",
    "\n",
    "  # Compute the self attention weights for the first and second head \n",
    "  self_attention_1 = all_values_1 @ softmax_cols(all_key_1.T @ all_query_1/np.sqrt(all_key_1.shape[0]))\n",
    "  self_attention_2 = all_values_2 @ softmax_cols(all_key_2.T @ all_query_2/np.sqrt(all_key_2.shape[0]))\n",
    "\n",
    "  # Concatenate the 2 computed self attention weights into one array\n",
    "  all_self_attention = np.concatenate([self_attention_1.T, self_attention_2.T], axis = 1)\n",
    "\n",
    "  # Compute dot product with concatenated array and weight to compute the output\n",
    "  X_prime = omega_c @ all_self_attention.T\n",
    "\n",
    "  return X_prime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468beebc-aa37-4070-a5da-565822b7d9b7",
   "metadata": {},
   "source": [
    "### Pass through the Multihead Self Attention Mechanism\n",
    "Using the defined hyperparameters, parameters, and input values, pass these values through the multihead self attention mechanism to compute an output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d07181eb-316b-476f-a8b5-7a7bce4cde69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_prime = multihead_scaled_self_attention(X,omega_v1, omega_q1, omega_k1, beta_v1, beta_q1, beta_k1, omega_v2, omega_q2, omega_k2, beta_v2, beta_q2, beta_k2, omega_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99f82de-2db9-477e-aa0a-04edbdfca234",
   "metadata": {},
   "source": [
    "### Print Output\n",
    "Print the output of the multihead self attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8d9612d-f4d5-4ac0-983e-b2a0babf8daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:\n",
      "[[-21.207  -5.373 -20.933  -9.179 -11.319 -17.812]\n",
      " [ -1.995   7.906 -10.516   3.452   9.863  -7.24 ]\n",
      " [  5.479   1.115   9.244   0.453   5.656   7.089]\n",
      " [ -7.413  -7.416   0.363  -5.573  -6.736  -0.848]\n",
      " [-11.261  -9.937  -4.848  -8.915 -13.378  -5.761]\n",
      " [  3.548  10.036  -2.244   1.604  12.113  -2.557]\n",
      " [  4.888  -5.814   2.407   3.228  -4.232   3.71 ]\n",
      " [  1.248  18.894  -6.409   3.224  19.717  -5.629]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=3)\n",
    "print(\"Answer:\")\n",
    "print(X_prime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RDKit)",
   "language": "python",
   "name": "rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
