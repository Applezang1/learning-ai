{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7a98330-f28b-42e5-9a84-bd6920cb0f22",
   "metadata": {},
   "source": [
    "# Double Descent \n",
    "This notebook aims to help gain a better understanding of double descent by defining a neural network model and training the neural network model over increasing model capacity (# of hidden units) to see how the error of the neural network model changes over model capacity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98c92c5-ad28-4056-9f37-c5c1457579b6",
   "metadata": {},
   "source": [
    "### Imports \n",
    "Import the libraries needed to define a neural network model, train a neural network model, and measure its error and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94dc9ca7-a696-481b-96f9-9af98484efa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist1d\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c84e14-2356-4b1e-a9a6-545763126a4d",
   "metadata": {},
   "source": [
    "### Define Processor Usage \n",
    "Check which processor (CPU or GPU) can be used to run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26f33ee0-21d9-4c82-867a-57e91e45837b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: cpu\n"
     ]
    }
   ],
   "source": [
    "DEVICE = str(torch.device('cuda' if torch.cuda.is_available() else 'cpu'))\n",
    "print('Using:', DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba8ab5e-7088-4348-af18-86bbd326db30",
   "metadata": {},
   "source": [
    "### Define Data \n",
    "Download and store the MNIST-1D dataset in its respective variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0aafa85-b5d3-4680-a4c4-3c7dbaec8712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Did or could not load data from ./mnist1d_data.pkl. Rebuilding dataset...\n"
     ]
    }
   ],
   "source": [
    "args = mnist1d.data.get_dataset_args()\n",
    "args.num_samples = 8000\n",
    "args.train_split = 0.5\n",
    "args.corr_noise_scale = 0.25\n",
    "args.iid_noise_scale=2e-2\n",
    "data = mnist1d.data.get_dataset(args, path='./mnist1d_data.pkl', download=False, regenerate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79aa09e-ce94-4ff1-a8aa-057d34b63920",
   "metadata": {},
   "source": [
    "### Add Variance to Data \n",
    "Add a 15% noise to the output of the training data to account for variance in data output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44739e2c-6f94-43c8-b849-e5c7a10d25c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c_y in range(len(data['y'])):\n",
    "    random_number = random.random()\n",
    "    if random_number < 0.15 :\n",
    "        random_int = int(random.random() * 10)\n",
    "        data['y'][c_y] = random_int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ec5960-1e4e-4a00-89c1-9f75d9556ffd",
   "metadata": {},
   "source": [
    "### Define Parameter \n",
    "Define a function that initializes the parameters using He initialization to avoid the shrinking or exploding gradient problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a3d612c-2da4-4bf0-a79c-79823d452fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(layer_in):\n",
    "  if isinstance(layer_in, nn.Linear):\n",
    "    nn.init.kaiming_uniform_(layer_in.weight)\n",
    "    layer_in.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4479b49a-b117-4226-86a5-54c28872a0db",
   "metadata": {},
   "source": [
    "### Define Model\n",
    "Define a neural network model with two hidden layers, each with a n_hidden amount of hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0ef61db-1b36-4a61-a1c6-45c0d2998a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(n_hidden):\n",
    "\n",
    "  D_i = 40    # Input dimensions\n",
    "  D_k = n_hidden   # Hidden dimensions\n",
    "  D_o = 10    # Output dimensions\n",
    "\n",
    "  # Define a model with two hidden layers, each undergoing ReLU functions\n",
    "  model = nn.Sequential(\n",
    "  nn.Linear(D_i, D_k),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(D_k, D_k),\n",
    "  nn.ReLU(),\n",
    "  nn.Linear(D_k, D_o))\n",
    "\n",
    "  # Initalize parameters\n",
    "  model.apply(weights_init)\n",
    "\n",
    "  # Return the model\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce1489f-ec12-428f-a8d6-60d871a202ec",
   "metadata": {},
   "source": [
    "### Define Training Function\n",
    "Define a function that fits the neural network model to the true function through stochastic gradient descent. For each 100 epoch (loop through the entire dataset), print out the neural network model's loss and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09287122-271a-4eb3-9b98-202d91adaa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, data, n_epoch):\n",
    "  # Define the loss function as the cross entropy loss function \n",
    "  loss_function = torch.nn.CrossEntropyLoss()\n",
    "  # Define a SGD optimizer and initialize learning rate and momentum\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum=0.9)\n",
    "  \n",
    "  x_train = torch.tensor(data['x'].astype('float32'))\n",
    "  y_train = torch.tensor(data['y'].transpose().astype('long'))\n",
    "  x_test= torch.tensor(data['x_test'].astype('float32'))\n",
    "  y_test = torch.tensor(data['y_test'].astype('long'))\n",
    "\n",
    "  # Separate data into batches for SGD optimizer\n",
    "  data_loader = DataLoader(TensorDataset(x_train,y_train), batch_size=100, shuffle=True, worker_init_fn=np.random.seed(1))\n",
    "\n",
    "  # Train over multiple cycles of the entire dataset (epoch)\n",
    "  for epoch in range(n_epoch):\n",
    "    # Look over batches\n",
    "    for i, batch in enumerate(data_loader):\n",
    "      # Retrieve inputs and labels for this batch\n",
    "      x_batch, y_batch = batch\n",
    "      # Reset the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "      # Compute the forward pass to calculate model output\n",
    "      pred = model(x_batch)\n",
    "      # Compute the loss\n",
    "      loss = loss_function(pred, y_batch)\n",
    "      # Compute the backward pass to calculate the gradients for SGD update\n",
    "      loss.backward()\n",
    "      # SGD update\n",
    "      optimizer.step()\n",
    "\n",
    "    # Compute statistics by running the enitre dataset\n",
    "    pred_train = model(x_train)\n",
    "    pred_test = model(x_test)\n",
    "    _, predicted_train_class = torch.max(pred_train.data, 1)\n",
    "    _, predicted_test_class = torch.max(pred_test.data, 1)\n",
    "    errors_train = 100 - 100 * (predicted_train_class == y_train).float().sum() / len(y_train)\n",
    "    errors_test= 100 - 100 * (predicted_test_class == y_test).float().sum() / len(y_test)\n",
    "    losses_train = loss_function(pred_train, y_train).item()\n",
    "    losses_test= loss_function(pred_test, y_test).item()\n",
    "    if epoch%100 ==0 :\n",
    "      print(f'Epoch {epoch:5d}, train loss {losses_train:.6f}, train error {errors_train:3.2f},  test loss {losses_test:.6f}, test error {errors_test:3.2f}')\n",
    "\n",
    "  return errors_train, errors_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4123a39a-8d39-4780-bafe-14ee6224a6ba",
   "metadata": {},
   "source": [
    "### Define Capacity Function\n",
    "Define a function to measure a neural network model's capacity (# of parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "902faa0c-81a9-4cb2-a2e8-ba72b99c8c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cdbf343-ea73-4c00-8465-ea6af004d787",
   "metadata": {},
   "source": [
    "### Define Hidden Units \n",
    "Define a number of different hidden units in order to determine how model behavior changes with an increasing amount of hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffbaee55-6a05-4c49-8b17-235f420a5ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_variables = np.array([2,4,6,8,10,14,18,22,26,30,35,40,45,50,55,60,70,80,90,100,120,140,160,180,200,250,300,400]) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6f1fce-51c2-4705-9032-d1cadb45904b",
   "metadata": {},
   "source": [
    "### Define Parameter Array Structure\n",
    "Define array structures to store the error from the training set, error from the test set, and the total number of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2370017f-619b-42f0-8740-aeee13a4cb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_train_all = np.zeros_like(hidden_variables)\n",
    "errors_test_all = np.zeros_like(hidden_variables)\n",
    "total_weights_all = np.zeros_like(hidden_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c15706-4460-4f35-a1db-32722452aaf3",
   "metadata": {},
   "source": [
    "### Define Epoch \n",
    "Define the number of times to loop over the dataset for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ee9dcab-8fe4-447a-b5b7-2e269c572853",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epoch = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155c43be-47c1-407e-94e0-3f3a5c234e63",
   "metadata": {},
   "source": [
    "### Train Neural Network Model\n",
    "Train the neural network model n_epoch times over each number of hidden units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7601bd6-07a4-471c-a5e9-579d29b10e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model with   2 hidden variables\n",
      "Epoch     0, train loss 2.302655, train error 89.90,  test loss 2.304593, test error 90.07\n",
      "Epoch   100, train loss 1.884592, train error 69.95,  test loss 1.732363, test error 68.82\n",
      "Epoch   200, train loss 1.872290, train error 70.80,  test loss 1.701079, test error 68.00\n",
      "Epoch   300, train loss 1.865688, train error 71.30,  test loss 1.708164, test error 68.07\n",
      "Epoch   400, train loss 1.861487, train error 70.93,  test loss 1.704003, test error 68.20\n",
      "Epoch   500, train loss 1.859760, train error 71.00,  test loss 1.704987, test error 68.10\n",
      "Epoch   600, train loss 1.859041, train error 70.97,  test loss 1.704983, test error 68.10\n",
      "Epoch   700, train loss 1.861792, train error 71.50,  test loss 1.700918, test error 68.82\n",
      "Epoch   800, train loss 1.860398, train error 70.57,  test loss 1.717716, test error 67.90\n",
      "Epoch   900, train loss 1.858098, train error 70.80,  test loss 1.706780, test error 68.65\n",
      "Training model with   4 hidden variables\n",
      "Epoch     0, train loss 2.241110, train error 83.47,  test loss 2.225417, test error 82.65\n",
      "Epoch   100, train loss 1.869192, train error 68.28,  test loss 1.725446, test error 67.15\n",
      "Epoch   200, train loss 1.793339, train error 62.30,  test loss 1.625693, test error 60.92\n",
      "Epoch   300, train loss 1.795729, train error 61.92,  test loss 1.625586, test error 60.08\n",
      "Epoch   400, train loss 1.777173, train error 61.33,  test loss 1.614794, test error 59.65\n",
      "Epoch   500, train loss 1.758502, train error 60.42,  test loss 1.597326, test error 59.10\n",
      "Epoch   600, train loss 1.746178, train error 60.00,  test loss 1.590675, test error 58.55\n",
      "Epoch   700, train loss 1.739426, train error 60.40,  test loss 1.584122, test error 57.97\n",
      "Epoch   800, train loss 1.736795, train error 60.33,  test loss 1.586517, test error 58.50\n",
      "Epoch   900, train loss 1.745842, train error 61.12,  test loss 1.568460, test error 58.97\n",
      "Training model with   6 hidden variables\n",
      "Epoch     0, train loss 2.214699, train error 83.53,  test loss 2.198252, test error 82.60\n",
      "Epoch   100, train loss 1.697068, train error 61.80,  test loss 1.518779, test error 59.10\n",
      "Epoch   200, train loss 1.644856, train error 58.58,  test loss 1.461851, test error 56.45\n",
      "Epoch   300, train loss 1.628904, train error 58.92,  test loss 1.454811, test error 55.72\n",
      "Epoch   400, train loss 1.636522, train error 59.17,  test loss 1.460800, test error 55.58\n",
      "Epoch   500, train loss 1.623350, train error 58.00,  test loss 1.454049, test error 55.15\n",
      "Epoch   600, train loss 1.617936, train error 58.08,  test loss 1.448425, test error 55.22\n",
      "Epoch   700, train loss 1.615615, train error 58.22,  test loss 1.452340, test error 56.45\n",
      "Epoch   800, train loss 1.616624, train error 58.78,  test loss 1.464367, test error 55.20\n",
      "Epoch   900, train loss 1.617189, train error 58.65,  test loss 1.468286, test error 56.42\n",
      "Training model with   8 hidden variables\n",
      "Epoch     0, train loss 2.248538, train error 85.05,  test loss 2.229865, test error 83.07\n",
      "Epoch   100, train loss 1.520748, train error 52.47,  test loss 1.347790, test error 49.47\n",
      "Epoch   200, train loss 1.494838, train error 50.92,  test loss 1.323417, test error 48.83\n",
      "Epoch   300, train loss 1.475070, train error 50.22,  test loss 1.313470, test error 48.50\n",
      "Epoch   400, train loss 1.439152, train error 48.67,  test loss 1.280841, test error 47.50\n",
      "Epoch   500, train loss 1.429898, train error 48.60,  test loss 1.271922, test error 47.33\n",
      "Epoch   600, train loss 1.421825, train error 48.25,  test loss 1.271152, test error 46.42\n",
      "Epoch   700, train loss 1.418142, train error 47.90,  test loss 1.261560, test error 46.50\n",
      "Epoch   800, train loss 1.416507, train error 47.47,  test loss 1.270574, test error 46.60\n",
      "Epoch   900, train loss 1.417811, train error 48.33,  test loss 1.274069, test error 46.65\n",
      "Training model with  10 hidden variables\n",
      "Epoch     0, train loss 2.223418, train error 83.12,  test loss 2.212982, test error 82.78\n",
      "Epoch   100, train loss 1.541585, train error 52.42,  test loss 1.400568, test error 52.90\n",
      "Epoch   200, train loss 1.455099, train error 49.62,  test loss 1.302287, test error 48.50\n",
      "Epoch   300, train loss 1.421572, train error 48.38,  test loss 1.308839, test error 49.62\n",
      "Epoch   400, train loss 1.405048, train error 48.47,  test loss 1.310201, test error 48.28\n",
      "Epoch   500, train loss 1.392594, train error 47.08,  test loss 1.301758, test error 48.33\n",
      "Epoch   600, train loss 1.383821, train error 46.80,  test loss 1.307563, test error 48.10\n",
      "Epoch   700, train loss 1.378286, train error 47.38,  test loss 1.303563, test error 47.72\n",
      "Epoch   800, train loss 1.367803, train error 46.80,  test loss 1.305735, test error 47.62\n",
      "Epoch   900, train loss 1.370075, train error 46.78,  test loss 1.315501, test error 48.28\n",
      "Training model with  14 hidden variables\n",
      "Epoch     0, train loss 2.270339, train error 86.12,  test loss 2.268482, test error 84.50\n",
      "Epoch   100, train loss 1.467834, train error 50.00,  test loss 1.398031, test error 52.15\n",
      "Epoch   200, train loss 1.391789, train error 47.90,  test loss 1.417301, test error 51.83\n",
      "Epoch   300, train loss 1.361302, train error 47.22,  test loss 1.417761, test error 51.50\n",
      "Epoch   400, train loss 1.345260, train error 45.90,  test loss 1.441211, test error 52.03\n",
      "Epoch   500, train loss 1.342631, train error 45.88,  test loss 1.453067, test error 53.03\n",
      "Epoch   600, train loss 1.329582, train error 45.50,  test loss 1.460514, test error 52.65\n",
      "Epoch   700, train loss 1.330311, train error 46.35,  test loss 1.479048, test error 52.80\n",
      "Epoch   800, train loss 1.318578, train error 45.12,  test loss 1.471786, test error 52.80\n",
      "Epoch   900, train loss 1.314569, train error 45.80,  test loss 1.494857, test error 53.17\n",
      "Training model with  18 hidden variables\n",
      "Epoch     0, train loss 2.215415, train error 81.97,  test loss 2.193148, test error 81.20\n",
      "Epoch   100, train loss 1.403627, train error 47.65,  test loss 1.364838, test error 51.25\n",
      "Epoch   200, train loss 1.275704, train error 43.62,  test loss 1.397138, test error 51.05\n",
      "Epoch   300, train loss 1.230800, train error 42.03,  test loss 1.398372, test error 49.78\n",
      "Epoch   400, train loss 1.211215, train error 42.12,  test loss 1.400287, test error 50.30\n",
      "Epoch   500, train loss 1.191701, train error 41.15,  test loss 1.419590, test error 50.78\n",
      "Epoch   600, train loss 1.169573, train error 39.92,  test loss 1.457747, test error 50.85\n",
      "Epoch   700, train loss 1.152516, train error 39.15,  test loss 1.474412, test error 50.28\n",
      "Epoch   800, train loss 1.146371, train error 39.40,  test loss 1.517005, test error 51.28\n",
      "Epoch   900, train loss 1.138012, train error 39.17,  test loss 1.549942, test error 50.92\n",
      "Training model with  22 hidden variables\n",
      "Epoch     0, train loss 2.258582, train error 83.28,  test loss 2.245794, test error 82.45\n",
      "Epoch   100, train loss 1.251906, train error 40.97,  test loss 1.245178, test error 46.12\n",
      "Epoch   200, train loss 1.140195, train error 37.72,  test loss 1.341588, test error 48.05\n",
      "Epoch   300, train loss 1.082913, train error 36.33,  test loss 1.419487, test error 49.35\n",
      "Epoch   400, train loss 1.058461, train error 35.93,  test loss 1.506354, test error 50.30\n",
      "Epoch   500, train loss 1.015473, train error 34.03,  test loss 1.584640, test error 51.62\n",
      "Epoch   600, train loss 0.999107, train error 34.20,  test loss 1.623780, test error 51.60\n",
      "Epoch   700, train loss 0.979893, train error 33.75,  test loss 1.697635, test error 52.10\n",
      "Epoch   800, train loss 0.967257, train error 33.00,  test loss 1.753589, test error 51.60\n",
      "Epoch   900, train loss 0.963942, train error 32.78,  test loss 1.832469, test error 52.78\n",
      "Training model with  26 hidden variables\n",
      "Epoch     0, train loss 2.189236, train error 81.05,  test loss 2.181757, test error 80.22\n",
      "Epoch   100, train loss 1.207433, train error 40.45,  test loss 1.315722, test error 49.50\n",
      "Epoch   200, train loss 1.044818, train error 35.53,  test loss 1.437431, test error 50.62\n",
      "Epoch   300, train loss 0.970938, train error 32.68,  test loss 1.553442, test error 50.58\n",
      "Epoch   400, train loss 0.946121, train error 31.62,  test loss 1.676996, test error 52.80\n",
      "Epoch   500, train loss 0.913962, train error 31.15,  test loss 1.752761, test error 53.38\n",
      "Epoch   600, train loss 0.891020, train error 30.60,  test loss 1.846041, test error 54.38\n",
      "Epoch   700, train loss 0.869494, train error 30.68,  test loss 1.919277, test error 54.00\n",
      "Epoch   800, train loss 0.855061, train error 29.70,  test loss 1.980830, test error 54.80\n",
      "Epoch   900, train loss 0.837305, train error 28.95,  test loss 2.022414, test error 54.62\n",
      "Training model with  30 hidden variables\n",
      "Epoch     0, train loss 2.196498, train error 81.78,  test loss 2.212390, test error 82.10\n",
      "Epoch   100, train loss 1.086004, train error 34.88,  test loss 1.331548, test error 49.42\n",
      "Epoch   200, train loss 0.910102, train error 29.90,  test loss 1.525982, test error 50.85\n",
      "Epoch   300, train loss 0.839634, train error 27.88,  test loss 1.727012, test error 52.60\n",
      "Epoch   400, train loss 0.776525, train error 26.28,  test loss 1.889217, test error 54.20\n",
      "Epoch   500, train loss 0.740438, train error 24.70,  test loss 2.054554, test error 54.92\n",
      "Epoch   600, train loss 0.724616, train error 24.78,  test loss 2.187498, test error 54.55\n",
      "Epoch   700, train loss 0.708303, train error 24.38,  test loss 2.299729, test error 54.95\n",
      "Epoch   800, train loss 0.664849, train error 22.65,  test loss 2.390714, test error 56.35\n",
      "Epoch   900, train loss 0.659684, train error 22.62,  test loss 2.527626, test error 56.53\n",
      "Training model with  35 hidden variables\n",
      "Epoch     0, train loss 2.107821, train error 78.85,  test loss 2.055379, test error 78.28\n",
      "Epoch   100, train loss 1.025391, train error 33.50,  test loss 1.383260, test error 49.97\n",
      "Epoch   200, train loss 0.802003, train error 27.20,  test loss 1.756040, test error 52.60\n",
      "Epoch   300, train loss 0.667780, train error 22.25,  test loss 2.160218, test error 55.30\n",
      "Epoch   400, train loss 0.596284, train error 20.18,  test loss 2.558956, test error 57.10\n",
      "Epoch   500, train loss 0.579560, train error 20.32,  test loss 2.891845, test error 57.00\n",
      "Epoch   600, train loss 0.519838, train error 18.28,  test loss 3.299220, test error 56.88\n",
      "Epoch   700, train loss 0.462053, train error 16.05,  test loss 3.659809, test error 57.53\n",
      "Epoch   800, train loss 0.465617, train error 16.53,  test loss 4.015103, test error 57.70\n",
      "Epoch   900, train loss 0.451193, train error 15.90,  test loss 4.370468, test error 58.92\n",
      "Training model with  40 hidden variables\n",
      "Epoch     0, train loss 2.073641, train error 77.80,  test loss 2.019825, test error 76.90\n",
      "Epoch   100, train loss 0.907473, train error 28.78,  test loss 1.420429, test error 48.65\n",
      "Epoch   200, train loss 0.662566, train error 20.85,  test loss 1.879894, test error 52.08\n",
      "Epoch   300, train loss 0.528701, train error 16.60,  test loss 2.427880, test error 54.05\n",
      "Epoch   400, train loss 0.407333, train error 13.53,  test loss 3.066622, test error 54.65\n",
      "Epoch   500, train loss 0.370886, train error 12.72,  test loss 3.820271, test error 55.78\n",
      "Epoch   600, train loss 0.363498, train error 12.90,  test loss 4.612045, test error 57.25\n",
      "Epoch   700, train loss 0.379204, train error 13.22,  test loss 5.282650, test error 57.17\n",
      "Epoch   800, train loss 0.258958, train error 9.20,  test loss 5.943809, test error 57.67\n",
      "Epoch   900, train loss 0.276615, train error 10.43,  test loss 6.494720, test error 56.25\n",
      "Training model with  45 hidden variables\n",
      "Epoch     0, train loss 2.066664, train error 76.53,  test loss 2.033257, test error 76.22\n",
      "Epoch   100, train loss 0.825345, train error 26.45,  test loss 1.555017, test error 52.05\n",
      "Epoch   200, train loss 0.484830, train error 14.93,  test loss 2.389449, test error 55.65\n",
      "Epoch   300, train loss 0.304858, train error 9.28,  test loss 3.554656, test error 57.03\n",
      "Epoch   400, train loss 0.214320, train error 7.18,  test loss 5.099792, test error 59.40\n",
      "Epoch   500, train loss 0.111488, train error 2.90,  test loss 6.600706, test error 59.40\n",
      "Epoch   600, train loss 0.104925, train error 3.12,  test loss 7.987224, test error 59.15\n",
      "Epoch   700, train loss 0.012240, train error 0.00,  test loss 9.098662, test error 59.80\n",
      "Epoch   800, train loss 0.008501, train error 0.00,  test loss 9.816246, test error 60.05\n",
      "Epoch   900, train loss 0.006364, train error 0.00,  test loss 10.383050, test error 59.92\n",
      "Training model with  50 hidden variables\n",
      "Epoch     0, train loss 2.074697, train error 77.78,  test loss 2.058710, test error 78.55\n",
      "Epoch   100, train loss 0.717573, train error 22.35,  test loss 1.583826, test error 50.12\n",
      "Epoch   200, train loss 0.360340, train error 10.85,  test loss 2.575252, test error 52.97\n",
      "Epoch   300, train loss 0.192631, train error 5.50,  test loss 3.957697, test error 53.92\n",
      "Epoch   400, train loss 0.093171, train error 2.43,  test loss 5.550709, test error 55.10\n",
      "Epoch   500, train loss 0.015444, train error 0.00,  test loss 6.583729, test error 55.25\n",
      "Epoch   600, train loss 0.009306, train error 0.00,  test loss 7.272593, test error 55.40\n",
      "Epoch   700, train loss 0.006609, train error 0.00,  test loss 7.785316, test error 55.58\n",
      "Epoch   800, train loss 0.005022, train error 0.00,  test loss 8.181463, test error 55.55\n",
      "Epoch   900, train loss 0.004031, train error 0.00,  test loss 8.512424, test error 55.58\n",
      "Training model with  55 hidden variables\n",
      "Epoch     0, train loss 2.066610, train error 77.50,  test loss 2.019263, test error 77.25\n",
      "Epoch   100, train loss 0.651100, train error 20.05,  test loss 1.644320, test error 51.10\n",
      "Epoch   200, train loss 0.239258, train error 6.30,  test loss 2.872680, test error 52.72\n",
      "Epoch   300, train loss 0.044838, train error 0.10,  test loss 4.569907, test error 54.65\n",
      "Epoch   400, train loss 0.014804, train error 0.00,  test loss 5.618872, test error 54.65\n",
      "Epoch   500, train loss 0.008477, train error 0.00,  test loss 6.250583, test error 54.88\n",
      "Epoch   600, train loss 0.005777, train error 0.00,  test loss 6.704033, test error 54.72\n",
      "Epoch   700, train loss 0.004289, train error 0.00,  test loss 7.046169, test error 54.97\n",
      "Epoch   800, train loss 0.003383, train error 0.00,  test loss 7.321712, test error 54.97\n",
      "Epoch   900, train loss 0.002761, train error 0.00,  test loss 7.552525, test error 54.97\n",
      "Training model with  60 hidden variables\n",
      "Epoch     0, train loss 2.043995, train error 75.55,  test loss 1.972075, test error 75.80\n",
      "Epoch   100, train loss 0.497884, train error 14.28,  test loss 1.740530, test error 50.25\n",
      "Epoch   200, train loss 0.083869, train error 0.28,  test loss 3.384666, test error 52.38\n",
      "Epoch   300, train loss 0.018112, train error 0.00,  test loss 4.640474, test error 52.80\n",
      "Epoch   400, train loss 0.008956, train error 0.00,  test loss 5.296968, test error 52.88\n",
      "Epoch   500, train loss 0.005678, train error 0.00,  test loss 5.731004, test error 52.72\n",
      "Epoch   600, train loss 0.004091, train error 0.00,  test loss 6.048591, test error 52.67\n",
      "Epoch   700, train loss 0.003144, train error 0.00,  test loss 6.311068, test error 52.60\n",
      "Epoch   800, train loss 0.002538, train error 0.00,  test loss 6.524839, test error 52.62\n",
      "Epoch   900, train loss 0.002116, train error 0.00,  test loss 6.706801, test error 52.72\n",
      "Training model with  70 hidden variables\n",
      "Epoch     0, train loss 2.062408, train error 76.53,  test loss 2.003426, test error 75.28\n",
      "Epoch   100, train loss 0.370727, train error 10.15,  test loss 1.950770, test error 51.78\n",
      "Epoch   200, train loss 0.033367, train error 0.00,  test loss 3.517946, test error 52.17\n",
      "Epoch   300, train loss 0.010910, train error 0.00,  test loss 4.279653, test error 52.85\n",
      "Epoch   400, train loss 0.006068, train error 0.00,  test loss 4.700584, test error 52.95\n",
      "Epoch   500, train loss 0.004074, train error 0.00,  test loss 4.991570, test error 52.75\n",
      "Epoch   600, train loss 0.003014, train error 0.00,  test loss 5.218397, test error 52.67\n",
      "Epoch   700, train loss 0.002367, train error 0.00,  test loss 5.401139, test error 52.65\n",
      "Epoch   800, train loss 0.001933, train error 0.00,  test loss 5.553332, test error 52.65\n",
      "Epoch   900, train loss 0.001622, train error 0.00,  test loss 5.683925, test error 52.80\n",
      "Training model with  80 hidden variables\n",
      "Epoch     0, train loss 2.048033, train error 76.40,  test loss 1.988033, test error 76.25\n",
      "Epoch   100, train loss 0.246124, train error 4.53,  test loss 2.133277, test error 52.35\n",
      "Epoch   200, train loss 0.021420, train error 0.00,  test loss 3.596185, test error 52.83\n",
      "Epoch   300, train loss 0.008396, train error 0.00,  test loss 4.176224, test error 53.53\n",
      "Epoch   400, train loss 0.004898, train error 0.00,  test loss 4.528519, test error 53.80\n",
      "Epoch   500, train loss 0.003383, train error 0.00,  test loss 4.779338, test error 54.05\n",
      "Epoch   600, train loss 0.002545, train error 0.00,  test loss 4.972490, test error 53.88\n",
      "Epoch   700, train loss 0.002019, train error 0.00,  test loss 5.131477, test error 53.97\n",
      "Epoch   800, train loss 0.001661, train error 0.00,  test loss 5.261606, test error 53.97\n",
      "Epoch   900, train loss 0.001404, train error 0.00,  test loss 5.377814, test error 54.08\n",
      "Training model with  90 hidden variables\n",
      "Epoch     0, train loss 1.985848, train error 73.10,  test loss 1.924818, test error 73.07\n",
      "Epoch   100, train loss 0.128922, train error 0.72,  test loss 2.199396, test error 51.30\n",
      "Epoch   200, train loss 0.014632, train error 0.00,  test loss 3.233686, test error 52.05\n",
      "Epoch   300, train loss 0.006465, train error 0.00,  test loss 3.641647, test error 52.15\n",
      "Epoch   400, train loss 0.003965, train error 0.00,  test loss 3.906697, test error 51.97\n",
      "Epoch   500, train loss 0.002795, train error 0.00,  test loss 4.095245, test error 52.15\n",
      "Epoch   600, train loss 0.002129, train error 0.00,  test loss 4.245544, test error 52.05\n",
      "Epoch   700, train loss 0.001705, train error 0.00,  test loss 4.365004, test error 52.08\n",
      "Epoch   800, train loss 0.001413, train error 0.00,  test loss 4.469055, test error 52.15\n",
      "Epoch   900, train loss 0.001200, train error 0.00,  test loss 4.557980, test error 52.17\n",
      "Training model with 100 hidden variables\n",
      "Epoch     0, train loss 1.972695, train error 73.53,  test loss 1.884881, test error 72.78\n",
      "Epoch   100, train loss 0.091346, train error 0.20,  test loss 2.243203, test error 51.62\n",
      "Epoch   200, train loss 0.011968, train error 0.00,  test loss 3.058168, test error 50.65\n",
      "Epoch   300, train loss 0.005605, train error 0.00,  test loss 3.411713, test error 50.75\n",
      "Epoch   400, train loss 0.003497, train error 0.00,  test loss 3.633372, test error 50.88\n",
      "Epoch   500, train loss 0.002489, train error 0.00,  test loss 3.796405, test error 50.90\n",
      "Epoch   600, train loss 0.001908, train error 0.00,  test loss 3.924472, test error 50.95\n",
      "Epoch   700, train loss 0.001535, train error 0.00,  test loss 4.030421, test error 50.92\n",
      "Epoch   800, train loss 0.001275, train error 0.00,  test loss 4.120551, test error 51.00\n",
      "Epoch   900, train loss 0.001086, train error 0.00,  test loss 4.198304, test error 51.00\n",
      "Training model with 120 hidden variables\n",
      "Epoch     0, train loss 1.980585, train error 73.32,  test loss 1.916131, test error 73.28\n",
      "Epoch   100, train loss 0.047856, train error 0.03,  test loss 2.206940, test error 49.83\n",
      "Epoch   200, train loss 0.009274, train error 0.00,  test loss 2.817265, test error 50.30\n",
      "Epoch   300, train loss 0.004616, train error 0.00,  test loss 3.093543, test error 50.35\n",
      "Epoch   400, train loss 0.002953, train error 0.00,  test loss 3.268130, test error 50.35\n",
      "Epoch   500, train loss 0.002131, train error 0.00,  test loss 3.398323, test error 50.22\n",
      "Epoch   600, train loss 0.001650, train error 0.00,  test loss 3.500112, test error 50.08\n",
      "Epoch   700, train loss 0.001334, train error 0.00,  test loss 3.584770, test error 50.12\n",
      "Epoch   800, train loss 0.001114, train error 0.00,  test loss 3.657453, test error 50.08\n",
      "Epoch   900, train loss 0.000952, train error 0.00,  test loss 3.720676, test error 50.10\n",
      "Training model with 140 hidden variables\n",
      "Epoch     0, train loss 1.979130, train error 71.97,  test loss 1.902183, test error 73.72\n",
      "Epoch   100, train loss 0.035819, train error 0.03,  test loss 2.191323, test error 49.55\n",
      "Epoch   200, train loss 0.007911, train error 0.00,  test loss 2.687106, test error 49.95\n",
      "Epoch   300, train loss 0.004049, train error 0.00,  test loss 2.922185, test error 49.85\n",
      "Epoch   400, train loss 0.002634, train error 0.00,  test loss 3.075359, test error 49.72\n",
      "Epoch   500, train loss 0.001918, train error 0.00,  test loss 3.189914, test error 49.72\n",
      "Epoch   600, train loss 0.001493, train error 0.00,  test loss 3.280349, test error 49.67\n",
      "Epoch   700, train loss 0.001213, train error 0.00,  test loss 3.355974, test error 49.80\n",
      "Epoch   800, train loss 0.001016, train error 0.00,  test loss 3.420127, test error 49.83\n",
      "Epoch   900, train loss 0.000871, train error 0.00,  test loss 3.475691, test error 49.72\n",
      "Training model with 160 hidden variables\n",
      "Epoch     0, train loss 1.938530, train error 72.07,  test loss 1.845434, test error 72.15\n",
      "Epoch   100, train loss 0.029465, train error 0.00,  test loss 2.040435, test error 48.97\n",
      "Epoch   200, train loss 0.007331, train error 0.00,  test loss 2.448024, test error 48.92\n",
      "Epoch   300, train loss 0.003830, train error 0.00,  test loss 2.648848, test error 49.05\n",
      "Epoch   400, train loss 0.002512, train error 0.00,  test loss 2.780568, test error 49.03\n",
      "Epoch   500, train loss 0.001836, train error 0.00,  test loss 2.878404, test error 49.15\n",
      "Epoch   600, train loss 0.001432, train error 0.00,  test loss 2.958557, test error 49.25\n",
      "Epoch   700, train loss 0.001166, train error 0.00,  test loss 3.023417, test error 49.22\n",
      "Epoch   800, train loss 0.000978, train error 0.00,  test loss 3.079845, test error 49.15\n",
      "Epoch   900, train loss 0.000839, train error 0.00,  test loss 3.128231, test error 49.17\n",
      "Training model with 180 hidden variables\n",
      "Epoch     0, train loss 1.922444, train error 70.07,  test loss 1.845560, test error 72.43\n",
      "Epoch   100, train loss 0.024228, train error 0.00,  test loss 2.075205, test error 49.17\n",
      "Epoch   200, train loss 0.006496, train error 0.00,  test loss 2.423256, test error 48.50\n",
      "Epoch   300, train loss 0.003475, train error 0.00,  test loss 2.596334, test error 48.45\n",
      "Epoch   400, train loss 0.002301, train error 0.00,  test loss 2.712993, test error 48.33\n",
      "Epoch   500, train loss 0.001692, train error 0.00,  test loss 2.800767, test error 48.03\n",
      "Epoch   600, train loss 0.001325, train error 0.00,  test loss 2.871173, test error 48.05\n",
      "Epoch   700, train loss 0.001082, train error 0.00,  test loss 2.929923, test error 48.00\n",
      "Epoch   800, train loss 0.000910, train error 0.00,  test loss 2.979336, test error 47.88\n",
      "Epoch   900, train loss 0.000783, train error 0.00,  test loss 3.023404, test error 47.80\n",
      "Training model with 200 hidden variables\n",
      "Epoch     0, train loss 1.935617, train error 70.78,  test loss 1.855144, test error 72.38\n",
      "Epoch   100, train loss 0.021059, train error 0.00,  test loss 1.974455, test error 48.20\n",
      "Epoch   200, train loss 0.006029, train error 0.00,  test loss 2.280643, test error 48.10\n",
      "Epoch   300, train loss 0.003279, train error 0.00,  test loss 2.438670, test error 47.80\n",
      "Epoch   400, train loss 0.002190, train error 0.00,  test loss 2.545525, test error 47.92\n",
      "Epoch   500, train loss 0.001618, train error 0.00,  test loss 2.626740, test error 47.92\n",
      "Epoch   600, train loss 0.001272, train error 0.00,  test loss 2.692197, test error 47.95\n",
      "Epoch   700, train loss 0.001040, train error 0.00,  test loss 2.746134, test error 48.20\n",
      "Epoch   800, train loss 0.000876, train error 0.00,  test loss 2.792265, test error 48.25\n",
      "Epoch   900, train loss 0.000754, train error 0.00,  test loss 2.833015, test error 48.22\n",
      "Training model with 250 hidden variables\n",
      "Epoch     0, train loss 1.905144, train error 69.55,  test loss 1.824892, test error 71.22\n",
      "Epoch   100, train loss 0.017329, train error 0.00,  test loss 1.868997, test error 46.08\n",
      "Epoch   200, train loss 0.005393, train error 0.00,  test loss 2.119984, test error 46.05\n",
      "Epoch   300, train loss 0.002992, train error 0.00,  test loss 2.253802, test error 46.10\n",
      "Epoch   400, train loss 0.002018, train error 0.00,  test loss 2.344409, test error 46.25\n",
      "Epoch   500, train loss 0.001500, train error 0.00,  test loss 2.412311, test error 46.20\n",
      "Epoch   600, train loss 0.001183, train error 0.00,  test loss 2.467336, test error 46.12\n",
      "Epoch   700, train loss 0.000971, train error 0.00,  test loss 2.514265, test error 46.17\n",
      "Epoch   800, train loss 0.000820, train error 0.00,  test loss 2.553867, test error 46.12\n",
      "Epoch   900, train loss 0.000707, train error 0.00,  test loss 2.588563, test error 46.05\n",
      "Training model with 300 hidden variables\n",
      "Epoch     0, train loss 1.864756, train error 66.93,  test loss 1.806835, test error 69.90\n",
      "Epoch   100, train loss 0.014266, train error 0.00,  test loss 1.930119, test error 46.92\n",
      "Epoch   200, train loss 0.004766, train error 0.00,  test loss 2.162628, test error 46.92\n",
      "Epoch   300, train loss 0.002705, train error 0.00,  test loss 2.289118, test error 47.10\n",
      "Epoch   400, train loss 0.001842, train error 0.00,  test loss 2.375478, test error 47.03\n",
      "Epoch   500, train loss 0.001379, train error 0.00,  test loss 2.440998, test error 47.15\n",
      "Epoch   600, train loss 0.001091, train error 0.00,  test loss 2.494072, test error 47.10\n",
      "Epoch   700, train loss 0.000898, train error 0.00,  test loss 2.538610, test error 47.03\n",
      "Epoch   800, train loss 0.000760, train error 0.00,  test loss 2.576667, test error 47.05\n",
      "Epoch   900, train loss 0.000657, train error 0.00,  test loss 2.610058, test error 47.12\n",
      "Training model with 400 hidden variables\n",
      "Epoch     0, train loss 1.856076, train error 66.35,  test loss 1.773819, test error 68.90\n",
      "Epoch   100, train loss 0.011513, train error 0.00,  test loss 1.761721, test error 46.25\n",
      "Epoch   200, train loss 0.004131, train error 0.00,  test loss 1.938406, test error 46.08\n",
      "Epoch   300, train loss 0.002399, train error 0.00,  test loss 2.038325, test error 46.05\n",
      "Epoch   400, train loss 0.001653, train error 0.00,  test loss 2.109120, test error 46.15\n",
      "Epoch   500, train loss 0.001246, train error 0.00,  test loss 2.161935, test error 46.12\n",
      "Epoch   600, train loss 0.000993, train error 0.00,  test loss 2.205825, test error 46.17\n",
      "Epoch   700, train loss 0.000821, train error 0.00,  test loss 2.242036, test error 46.10\n",
      "Epoch   800, train loss 0.000697, train error 0.00,  test loss 2.273737, test error 46.00\n",
      "Epoch   900, train loss 0.000604, train error 0.00,  test loss 2.301415, test error 45.97\n"
     ]
    }
   ],
   "source": [
    "for c_hidden in range(len(hidden_variables)):\n",
    "    print(f'Training model with {hidden_variables[c_hidden]:3d} hidden variables')\n",
    "    # Define a model\n",
    "    model = get_model(hidden_variables[c_hidden]) \n",
    "    # Count and store the number of weights\n",
    "    total_weights_all[c_hidden] = count_parameters(model)\n",
    "    # Train the model\n",
    "    errors_train, errors_test = fit_model(model, data, n_epoch)\n",
    "    # Store the results (errors on train and test set)\n",
    "    errors_train_all[c_hidden] = errors_train\n",
    "    errors_test_all[c_hidden]= errors_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba40226-c211-4b20-83aa-d44425220dc3",
   "metadata": {},
   "source": [
    "### Determine Line where Total Weights = Number of Training Examples\n",
    "Define a vertical line at the point where the total number of weights of the neural network equals the number of training examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba1b1044-0527-4ec5-a896-bafdebf912e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of training examples\n",
    "num_training_examples = len(data['y'])\n",
    "\n",
    "# Find the index where total_weights_all is closest to num_training_examples\n",
    "closest_index = np.argmin(np.abs(np.array(total_weights_all) - num_training_examples))\n",
    "\n",
    "# Compute the corresponding value of hidden variables\n",
    "hidden_variable_at_num_training_examples = hidden_variables[closest_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b6e30c-35f9-427c-9c82-9a7a9625ffe5",
   "metadata": {},
   "source": [
    "### Plot Results\n",
    "Plot the error of the test set and the training set of the neural network as a function of model capacity. In addition, add the defined vertical line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dae5f2e6-d764-424b-9e53-0a3a1731c326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(hidden_variables, errors_train_all, 'r-', label='train')\n",
    "ax.plot(hidden_variables, errors_test_all, 'b-', label='test')\n",
    "\n",
    "# Add a vertical line at the point where total weights equal the number of training examples\n",
    "ax.axvline(x=hidden_variable_at_num_training_examples, color='g', linestyle='--', label='N(weights) = N(train)')\n",
    "ax.set_ylim(0, 100)\n",
    "ax.set_xlabel('No. hidden variables')\n",
    "ax.set_ylabel('Error')\n",
    "ax.legend()\n",
    "plt.show()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RDKit)",
   "language": "python",
   "name": "rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
