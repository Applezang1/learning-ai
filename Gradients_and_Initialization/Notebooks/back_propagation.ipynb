{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "982e2969-a61a-4cf8-8c64-8fcfdd39137a",
   "metadata": {},
   "source": [
    "# Back Propagation \n",
    "This notebook aims to help gain an understanding of back propagation by applying the process to a neural network model and double checking the accuracy of the back propagation by comparing the results with derivatives with finite differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f82eda1-3c33-429e-a0c6-b584533ebd00",
   "metadata": {},
   "source": [
    "### Imports\n",
    "Import the libraries needed to define the neural network and back propagation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08dd965e-c8c3-4185-a9c9-112f105f8c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad86d440-7357-45cc-9285-3976146f1c34",
   "metadata": {},
   "source": [
    "### Define Parameters \n",
    "Define the dimensions of the neural network model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7594c323-864e-40cd-8ae1-16089e680f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed in order to consistently obtain the same random number\n",
    "np.random.seed(0)\n",
    "\n",
    "# Number of hidden layers\n",
    "K = 5\n",
    "# Number of neurons per layer\n",
    "D = 6\n",
    "# Input layer\n",
    "D_i = 1\n",
    "# Output layer\n",
    "D_o = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab00845-198d-412f-83b4-f018572cb086",
   "metadata": {},
   "source": [
    "### Define Weight and Bias Structure \n",
    "Define a list for the weights and biases in order to store all the weight and bias values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a20062be-1f73-4a0e-ab77-7cef53886b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights = [None] * (K+1)\n",
    "all_biases = [None] * (K+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9a3733-8970-4ccf-992e-a1afd9d29158",
   "metadata": {},
   "source": [
    "### Define Weight and Bias Values (First and Last)\n",
    "Define random values for the first and last layer of weights and biases and store these values in an array where each array corresponds to one hidden layer. Store the array as an element of the defined list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1be8ef-1a0b-4eeb-ad38-49071d17eca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weights[0] = np.random.normal(size=(D, D_i)) # First layer of weights\n",
    "all_weights[-1] = np.random.normal(size=(D_o, D)) # Last layer of weights\n",
    "all_biases[0] = np.random.normal(size =(D,1)) # First layer of biases\n",
    "all_biases[-1]= np.random.normal(size =(D_o,1)) # Last layer of biases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611d4e24-4942-450c-a02a-4f6087cf98c2",
   "metadata": {},
   "source": [
    "### Define Weight and Bias Values (Intermediate)\n",
    "Define random values for the weights and biases in the intermediate hidden layers and store these values in an array, where each array corresponds to one hidden layer. Store the array as an element in the defined list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1698e69c-367f-4063-8d1b-f5a9288b3e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(1,K):\n",
    "  all_weights[layer] = np.random.normal(size=(D,D))\n",
    "  all_biases[layer] = np.random.normal(size=(D,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c39f629-fa65-4baa-8883-7f2c1d40e829",
   "metadata": {},
   "source": [
    "### Define the Rectified Linear Unit (ReLU) Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2086e673-a4c8-4cf8-90e5-06e6acead308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReLU(preactivation):\n",
    "  activation = preactivation.clip(0.0)\n",
    "  return activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04394e6c-d670-4228-a938-7efd95dfdbb3",
   "metadata": {},
   "source": [
    "### Define Neural Network \n",
    "Define a function to define and compute a neural network, where the function takes in the inputs, weights, and biases and returns an output of the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc87c98c-f2f4-44ea-add5-ee80cf233410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_network_output(net_input, all_weights, all_biases):\n",
    "\n",
    "  # Retrieve number of layers\n",
    "  K = len(all_weights) -1\n",
    "  \n",
    "  # Store the pre-activations (all_f) and the activations (all_h)\n",
    "  all_f = [None] * (K+1)\n",
    "  all_h = [None] * (K+1)\n",
    "\n",
    "  all_h[0] = net_input\n",
    "\n",
    "  # Calculate the pre-activation and activation for each hidden layer\n",
    "  for layer in range(K):\n",
    "      # Compute the pre-activation function\n",
    "      all_f[layer] = all_biases[layer] + np.matmul(all_weights[layer], all_h[layer])\n",
    "      # Compute the activation function\n",
    "      all_h[layer+1] = ReLU(all_f[layer])\n",
    "\n",
    "  # Compute the output of the neural network from the last hidden layer\n",
    "  all_f[K] = all_biases[K] + np.matmul(all_weights[K], all_h[K])\n",
    "\n",
    "  # Retrieve the output\n",
    "  net_output = all_f[K]\n",
    "\n",
    "  return net_output, all_f, all_h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306f3bc1-e468-4480-8556-e49f81507ee8",
   "metadata": {},
   "source": [
    "### Define Input Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "596301eb-78e0-4c1f-b230-2e0599991e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_input = np.ones((D_i,1)) * 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48f8a0f-0694-40c4-8665-fb7d6061cdee",
   "metadata": {},
   "source": [
    "### Compute Neural Network\n",
    "Compute the neural network using the defined input value and print the output of the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a126a00-2687-4dea-8d5c-4db708f9a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True output = 1.907, Your answer = 1.907\n"
     ]
    }
   ],
   "source": [
    "net_output, all_f, all_h = compute_network_output(net_input,all_weights, all_biases)\n",
    "print(\"True output = %3.3f, Your answer = %3.3f\"%(1.907, net_output[0,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795f1f09-67b6-438e-8ef0-33ac16cb8b74",
   "metadata": {},
   "source": [
    "### Define Loss Function \n",
    "Define the least squares loss function as the loss function for this neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b4b8f35-b238-4d44-a356-6e4babd321f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_squares_loss(net_output, y):\n",
    "  return np.sum((net_output-y) * (net_output-y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c8ec5b-c473-44e5-a04e-22ab2f3d454d",
   "metadata": {},
   "source": [
    "### Define the Derivative of the Least Squares Loss Function (with respect to net_output)\n",
    "Define a function to take the derivative of the least squares loss function with respect to the variable net_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3dd3dad-f1ca-473a-81c3-35cbd43c821f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def d_loss_d_output(net_output, y):\n",
    "    return 2*(net_output -y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9f2ce2-1635-40b4-83c5-84691bac9e25",
   "metadata": {},
   "source": [
    "### Define Output Values\n",
    "Define ideal output values for the least squares loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aae3492a-1876-402a-9907-56f583b1879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.ones((D_o,1)) * 20.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3bc416-804f-4685-a1c5-02b4bfb8fd11",
   "metadata": {},
   "source": [
    "### Compute the Loss\n",
    "Compute the loss of the neural network by using the defined output value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "724622d0-5ba6-42eb-a120-2834a22c6008",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = least_squares_loss(net_output, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f81e29db-74e1-42d4-b377-a2208ea369f6",
   "metadata": {},
   "source": [
    "### Define an Indicator Function \n",
    "Define an indicator function for the backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edb1aeff-fa12-4524-b60a-897b7a4941ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_function(x):\n",
    "  x_in = np.array(x)\n",
    "  x_in[x_in>0] = 1\n",
    "  x_in[x_in<=0] = 0\n",
    "  return x_in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0806cb9-238c-44a1-9455-1b84c846abb7",
   "metadata": {},
   "source": [
    "## Backward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b714ad61-b714-427c-adc0-3fbe5df2bb85",
   "metadata": {},
   "source": [
    "### Define a Backward Pass\n",
    "Define a function that calculates the backward pass by computing the derivatives of the loss function with respect to the preactivations, activations, biases, and weights respectively. Return the derivative of the loss function with respect to the weights and the derivative of the loss function with respect to the biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "691fb1e7-6875-45b6-884e-0f1d07ba45a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function for the main backward pass\n",
    "def backward_pass(all_weights, all_biases, all_f, all_h, y):\n",
    "  # Store the derivatives dl_dweights and dl_dbiases in lists\n",
    "  all_dl_dweights = [None] * (K+1)\n",
    "  all_dl_dbiases = [None] * (K+1)\n",
    "  # Store the derivatives of the loss with respect to the activation and preactivations in lists\n",
    "  all_dl_df = [None] * (K+1)\n",
    "  all_dl_dh = [None] * (K+1)\n",
    "\n",
    "  # Compute derivatives of the loss with respect to the network output\n",
    "  all_dl_df[K] = np.array(d_loss_d_output(all_f[K],y))\n",
    "\n",
    "  # Compute the backward pass\n",
    "  for layer in range(K,-1,-1):\n",
    "    # Calculate the derivatives of the loss with respect to the biases at layer\n",
    "    all_dl_dbiases[layer] = all_dl_df[layer]\n",
    "\n",
    "    # Calculate the derivatives of the loss with respect to the weights at layer\n",
    "    all_dl_dweights[layer] = np.matmul(all_dl_df[layer], all_h[layer].T)\n",
    "\n",
    "    # Calculate the derivatives of the loss with respect to the activations\n",
    "    all_dl_dh[layer] = np.matmul(all_weights[layer].T, all_dl_df[layer])\n",
    "\n",
    "    if layer > 0:\n",
    "      # Calculate the derivatives of the loss with respect to the pre-activation f\n",
    "      all_dl_df[layer-1] = indicator_function(all_f[layer-1])*np.matmul(all_weights[layer].T, all_dl_df[layer])\n",
    "\n",
    "  return all_dl_dweights, all_dl_dbiases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702f78f1-dfc0-4481-a5d6-0fa5eb81b947",
   "metadata": {},
   "source": [
    "### Compute the Backward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fca35166-b393-4b69-bd55-9c770b70cb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dl_dweights, all_dl_dbiases = backward_pass(all_weights, all_biases, all_f, all_h, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf6bde3-6036-418a-b566-d34b4ed80a1e",
   "metadata": {},
   "source": [
    "## Confirm Backward Pass\n",
    "Confirm whether the backward pass was computed correctly by computing all the derivatives of the loss function with respect to the preactivations, activations, biases, and weights respectively with finite differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "142b1c70-a4bf-4b03-810e-7618fe16ccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d32d6b-fc6a-4bb0-a26b-30776e404953",
   "metadata": {},
   "source": [
    "### Define Weight and Bias Structure \n",
    "Define a list for the weights and biases in order to store all the weight and bias values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5c4b5d6-fb99-4cf6-be1f-1baedfd5fb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dl_dweights_fd = [None] * (K+1)\n",
    "all_dl_dbiases_fd = [None] * (K+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b42f658-13ee-41ec-85eb-700aad136cd4",
   "metadata": {},
   "source": [
    "### Define the Finite Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "effe4805-b587-4540-970a-ca0241d6b753",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_fd = 0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b86ca7c-eacb-49b5-8900-caafcf74bb79",
   "metadata": {},
   "source": [
    "### Test the Derivatives of the Bias Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3fbc204b-5166-4f9b-b866-8fc76bf2e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Bias 0, derivatives from backprop:\n",
      "[[ -4.48594876]\n",
      " [  4.94744466]\n",
      " [  6.81152875]\n",
      " [ -3.88346281]\n",
      " [-24.93526672]\n",
      " [  0.        ]]\n",
      "Bias 0, derivatives from finite differences\n",
      "[[ -4.48594881]\n",
      " [  4.94744461]\n",
      " [  6.81152875]\n",
      " [ -3.88346285]\n",
      " [-24.93526625]\n",
      " [  0.        ]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Bias 1, derivatives from backprop:\n",
      "[[ -0.        ]\n",
      " [-11.29689608]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [-10.72177079]\n",
      " [  0.        ]]\n",
      "Bias 1, derivatives from finite differences\n",
      "[[  0.        ]\n",
      " [-11.29689599]\n",
      " [  0.        ]\n",
      " [  0.        ]\n",
      " [-10.72177071]\n",
      " [  0.        ]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Bias 2, derivatives from backprop:\n",
      "[[-0.        ]\n",
      " [-0.        ]\n",
      " [ 0.93788659]\n",
      " [ 0.        ]\n",
      " [-9.99335294]\n",
      " [ 0.50756642]]\n",
      "Bias 2, derivatives from finite differences\n",
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.93788645]\n",
      " [ 0.        ]\n",
      " [-9.99335293]\n",
      " [ 0.50756631]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Bias 3, derivatives from backprop:\n",
      "[[-0.        ]\n",
      " [-4.7999531 ]\n",
      " [-1.66135975]\n",
      " [-0.        ]\n",
      " [ 3.39345428]\n",
      " [ 5.3909644 ]]\n",
      "Bias 3, derivatives from finite differences\n",
      "[[ 0.        ]\n",
      " [-4.7999531 ]\n",
      " [-1.66135982]\n",
      " [ 0.        ]\n",
      " [ 3.39345416]\n",
      " [ 5.39096436]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Bias 4, derivatives from backprop:\n",
      "[[-0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-0.        ]\n",
      " [-5.21247446]\n",
      " [-0.        ]]\n",
      "Bias 4, derivatives from finite differences\n",
      "[[ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [ 0.        ]\n",
      " [-5.21247449]\n",
      " [ 0.        ]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Bias 5, derivatives from backprop:\n",
      "[[-36.18679]]\n",
      "Bias 5, derivatives from finite differences\n",
      "[[-36.18678903]]\n",
      "Success!  Derivatives match.\n"
     ]
    }
   ],
   "source": [
    "for layer in range(K+1):\n",
    "  dl_dbias  = np.zeros_like(all_dl_dbiases[layer])\n",
    "  # For every element in the bias\n",
    "  for row in range(all_biases[layer].shape[0]):\n",
    "    # Take copy of biases and change one element at a time\n",
    "    all_biases_copy = [np.array(x) for x in all_biases]\n",
    "    all_biases_copy[layer][row] += delta_fd\n",
    "    network_output_1, *_ = compute_network_output(net_input, all_weights, all_biases_copy)\n",
    "    network_output_2, *_ = compute_network_output(net_input, all_weights, all_biases)\n",
    "    dl_dbias[row] = (least_squares_loss(network_output_1, y) - least_squares_loss(network_output_2,y))/delta_fd\n",
    "  all_dl_dbiases_fd[layer] = np.array(dl_dbias)\n",
    "  print(\"-----------------------------------------------\")\n",
    "  print(\"Bias %d, derivatives from backprop:\"%(layer))\n",
    "  print(all_dl_dbiases[layer])\n",
    "  print(\"Bias %d, derivatives from finite differences\"%(layer))\n",
    "  print(all_dl_dbiases_fd[layer])\n",
    "  if np.allclose(all_dl_dbiases_fd[layer],all_dl_dbiases[layer],rtol=1e-05, atol=1e-08, equal_nan=False):\n",
    "    print(\"Success!  Derivatives match.\")\n",
    "  else:\n",
    "    print(\"Failure!  Derivatives different.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fec554-d9ee-45f7-b615-551f6834c90b",
   "metadata": {},
   "source": [
    "### Test the Derivatives of the Weight Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36546b15-6d03-4ffe-a2c2-7e68eba9b601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "Weight 0, derivatives from backprop:\n",
      "[[ -5.38313851]\n",
      " [  5.93693359]\n",
      " [  8.1738345 ]\n",
      " [ -4.66015537]\n",
      " [-29.92232006]\n",
      " [  0.        ]]\n",
      "Weight 0, derivatives from finite differences\n",
      "[[ -5.38313856]\n",
      " [  5.93693352]\n",
      " [  8.17383454]\n",
      " [ -4.66015541]\n",
      " [-29.92231947]\n",
      " [  0.        ]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Weight 1, derivatives from backprop:\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [-32.51134334  -6.7991913  -18.28231837 -34.14764932 -42.19558628\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [-30.85618994  -6.45304428 -17.35156504 -32.40919155 -40.04740781\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]]\n",
      "Weight 1, derivatives from finite differences\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [-32.51134251  -6.79919128 -18.28231814 -34.14764848 -42.19558502\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [-30.85618926  -6.45304425 -17.35156491 -32.40919079 -40.04740663\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Weight 2, derivatives from backprop:\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           5.37135622   0.           0.           3.14460048\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.         -57.23278199   0.           0.         -33.50629267\n",
      "    0.        ]\n",
      " [  0.           2.90687606   0.           0.           1.7017981\n",
      "    0.        ]]\n",
      "Weight 2, derivatives from finite differences\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           5.37135622   0.           0.           3.14460038\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.         -57.23277951   0.           0.         -33.5062918\n",
      "    0.        ]\n",
      " [  0.           2.90687598   0.           0.           1.701798\n",
      "    0.        ]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Weight 3, derivatives from backprop:\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.          -3.67404472   0.         -42.90504609\n",
      "  -10.99843475]\n",
      " [  0.           0.          -1.27166035   0.         -14.85029441\n",
      "   -3.8067782 ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           2.59746346   0.          30.33286142\n",
      "    7.77563544]\n",
      " [  0.           0.           4.12642455   0.          48.1878825\n",
      "   12.35265615]]\n",
      "Weight 3, derivatives from finite differences\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.          -3.67404471   0.         -42.90504472\n",
      "  -10.99843473]\n",
      " [  0.           0.          -1.27166044   0.         -14.85029435\n",
      "   -3.80677824]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           2.59746338   0.          30.33286208\n",
      "    7.77563542]\n",
      " [  0.           0.           4.12642447   0.          48.18788426\n",
      "   12.35265614]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Weight 4, derivatives from backprop:\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.         -81.63541187 -49.13560664   0.         -22.00669771\n",
      "  -10.14554606]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]]\n",
      "Weight 4, derivatives from finite differences\n",
      "[[  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.         -81.63540684 -49.13560485   0.         -22.00669746\n",
      "  -10.14554607]\n",
      " [  0.           0.           0.           0.           0.\n",
      "    0.        ]]\n",
      "Success!  Derivatives match.\n",
      "-----------------------------------------------\n",
      "Weight 5, derivatives from backprop:\n",
      "[[   0.            0.            0.            0.         -400.33025447\n",
      "     0.        ]]\n",
      "Weight 5, derivatives from finite differences\n",
      "[[   0.            0.            0.            0.         -400.33013221\n",
      "     0.        ]]\n",
      "Success!  Derivatives match.\n"
     ]
    }
   ],
   "source": [
    "for layer in range(K+1):\n",
    "  dl_dweight  = np.zeros_like(all_dl_dweights[layer])\n",
    "  # For every element in the bias\n",
    "  for row in range(all_weights[layer].shape[0]):\n",
    "    for col in range(all_weights[layer].shape[1]):\n",
    "      # Take copy of biases and change one element at a time\n",
    "      all_weights_copy = [np.array(x) for x in all_weights]\n",
    "      all_weights_copy[layer][row][col] += delta_fd\n",
    "      network_output_1, *_ = compute_network_output(net_input, all_weights_copy, all_biases)\n",
    "      network_output_2, *_ = compute_network_output(net_input, all_weights, all_biases)\n",
    "      dl_dweight[row][col] = (least_squares_loss(network_output_1, y) - least_squares_loss(network_output_2,y))/delta_fd\n",
    "  all_dl_dweights_fd[layer] = np.array(dl_dweight)\n",
    "  print(\"-----------------------------------------------\")\n",
    "  print(\"Weight %d, derivatives from backprop:\"%(layer))\n",
    "  print(all_dl_dweights[layer])\n",
    "  print(\"Weight %d, derivatives from finite differences\"%(layer))\n",
    "  print(all_dl_dweights_fd[layer])\n",
    "  if np.allclose(all_dl_dweights_fd[layer],all_dl_dweights[layer],rtol=1e-05, atol=1e-08, equal_nan=False):\n",
    "    print(\"Success!  Derivatives match.\")\n",
    "  else:\n",
    "    print(\"Failure!  Derivatives different.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (RDKit)",
   "language": "python",
   "name": "rdkit-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
